<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>VISSL · A library for state-of-the-art self-supervised learning from images</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="A library for state-of-the-art self-supervised learning from images"/><meta property="og:title" content="VISSL · A library for state-of-the-art self-supervised learning from images"/><meta property="og:type" content="website"/><meta property="og:url" content="https://vissl.ai/"/><meta property="og:description" content="A library for state-of-the-art self-supervised learning from images"/><meta property="og:image" content="https://vissl.ai/img/vissllogo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://vissl.ai/img/vissllogo.svg"/><link rel="shortcut icon" href="/img/visslfavicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-172675973-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/visslfavicon.png" alt="VISSL"/><h2 class="headerTitleWithLogo">VISSL</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/tutorials" target="_self">Tutorials</a></li><li class=""><a href="https://vissl.readthedocs.io/" target="_self">Docs</a></li><li class=""><a href="https://github.com/facebookresearch/vissl" target="_self">GitHub</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Tutorials</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Getting Started</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Installation_v0_1_6">Installation</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Understanding_VISSL_Training_and_YAML_Config_V0_1_6">Understanding VISSL Training and YAML Config</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Training</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Train_SimCLR_on_1_gpu_V0_1_6">Train SimCLR on 1-gpu</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Feature Extraction</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/Feature_Extraction_V0_1_6">Feature Extraction</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Benchmark</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K_V0_1_6">Benchmark Linear Image Classification on ImageNet-1K</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6">Benchmark Full-Finetuning on ImageNet-1K</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Large Scale Training</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Large_Scale_Training_V0_1_6">Large Scale Training with VISSL (fp16, LARC, ZeRO, etc)</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Inference</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Using_a_pretrained_model_for_inference_V0_1_6">Using a pretrained model for inference</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="tutorialButtonsWrapper"><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Feature_Extraction_V0_1_6.ipynb" target="_blank"><img class="colabButton" align="left" src="/img/colab_icon.png"/>Run in Google Colab</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Feature_Extraction_V0_1_6.ipynb" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Jupyter Notebook</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Feature_Extraction_V0_1_6.py" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Source Code</a></div></div><div class="tutorialBody">
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js">
</script>
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js">
</script>
<div class="notebook">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Feature_Extraction_V0_1_6.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Feature-Extraction">Feature Extraction<a class="anchor-link" href="#Feature-Extraction">¶</a></h1><p>In this tutorial, we look at a simple example of how to use VISSL to extract features for <a href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16">ResNet-50 Torchvision pre-trained model</a>.</p>
<p>You can make a copy of this tutorial by <code>File -&gt; Open in playground mode</code> and make changes there. Please do <em>NOT</em> request access to this tutorial.</p>
<p><strong>NOTE:</strong> Please ensure your Collab Notebook has a GPU available. To ensure this, simply follow: <code>Edit -&gt; Notebook Settings -&gt; select GPU.</code></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Install-VISSL">Install VISSL<a class="anchor-link" href="#Install-VISSL">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Installing VISSL is straightfoward. We will install VISSL from source using pip, following the instructions from <a href="https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package">here</a>. Note, you can also install VISSL in a conda environment or from our conda/pip binaries.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Install pytorch version 1.8</span>
<span class="o">!</span>pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.8.0+cu101 <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html

<span class="c1"># install Apex by checking system settings: cuda version, pytorch version, and python version</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">version_str</span><span class="o">=</span><span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
    <span class="sa">f</span><span class="s2">"py3</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">minor</span><span class="si">}</span><span class="s2">_cu"</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"."</span><span class="p">,</span><span class="s2">""</span><span class="p">),</span>
    <span class="sa">f</span><span class="s2">"_pyt</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">version_str</span><span class="p">)</span>

<span class="c1"># install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)</span>
<span class="o">!</span>pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/<span class="o">{</span>version_str<span class="o">}</span>/download.html

<span class="c1"># # clone vissl repository and checkout latest version.</span>
<span class="o">!</span>git clone --recursive https://github.com/facebookresearch/vissl.git

<span class="o">%</span><span class="k">cd</span> vissl/

<span class="o">!</span>git checkout v0.1.6
<span class="o">!</span>git checkout -b v0.1.6

<span class="c1"># install vissl dependencies</span>
<span class="o">!</span>pip install --progress-bar off -r requirements.txt
<span class="o">!</span>pip install opencv-python

<span class="c1"># update classy vision install to commit compatible with v0.1.6</span>
<span class="o">!</span>pip uninstall -y classy_vision
<span class="o">!</span>pip install classy-vision@https://github.com/facebookresearch/ClassyVision/tarball/4785d5ee19d3bcedd5b28c1eb51ea1f59188b54d

<span class="c1"># Update fairscale to commit compatible with v0.1.6</span>
<span class="o">!</span>pip uninstall -y fairscale
<span class="o">!</span>pip install fairscale@https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6

<span class="c1"># install vissl dev mode (e stands for editable)</span>
<span class="o">!</span>pip install -e .<span class="o">[</span>dev<span class="o">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>VISSL should be successfuly installed by now and all the dependencies should be available.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">vissl</span>
<span class="kn">import</span> <span class="nn">tensorboard</span>
<span class="kn">import</span> <span class="nn">apex</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-the-ResNet-50-weights-from-Torchvision">Download the ResNet-50 weights from Torchvision<a class="anchor-link" href="#Download-the-ResNet-50-weights-from-Torchvision">¶</a></h2><p>We download the weights from the <a href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16">torchvision ResNet50 model</a>:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://download.pytorch.org/models/resnet50-19c8e357.pth -P /content/
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-dummy-dataset">Creating a dummy dataset<a class="anchor-link" href="#Creating-a-dummy-dataset">¶</a></h2><p>For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p /content/dummy_data/train/class1
<span class="o">!</span>mkdir -p /content/dummy_data/train/class2
<span class="o">!</span>mkdir -p /content/dummy_data/val/class1
<span class="o">!</span>mkdir -p /content/dummy_data/val/class2

<span class="c1"># create 2 classes in train and add 5 images per class</span>
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img5.jpg

<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img5.jpg

<span class="c1"># create 2 classes in val and add 5 images per class</span>
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img5.jpg

<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img5.jpg
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-the-custom-data-in-VISSL">Using the custom data in VISSL<a class="anchor-link" href="#Using-the-custom-data-in-VISSL">¶</a></h2><p>Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to <code>configs/config/dataset_catalog.py</code> file.</p>
<p><strong>NOTE</strong>: VISSL uses the specific <code>dataset_catalog.json</code> under the path <code>configs/config/dataset_catalog.json</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">json_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"dummy_data_folder"</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">"train"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">"/content/dummy_data/train"</span><span class="p">,</span> <span class="s2">"/content/dummy_data/train"</span>
      <span class="p">],</span>
      <span class="s2">"val"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">"/content/dummy_data/val"</span><span class="p">,</span> <span class="s2">"/content/dummy_data/val"</span>
      <span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># use VISSL's api to save or you can use your custom code.</span>
<span class="kn">from</span> <span class="nn">vissl.utils.io</span> <span class="kn">import</span> <span class="n">save_file</span>
<span class="n">save_file</span><span class="p">(</span><span class="n">json_data</span><span class="p">,</span> <span class="s2">"/content/vissl/configs/config/dataset_catalog.json"</span><span class="p">,</span> <span class="n">append_to_json</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">vissl.data.dataset_catalog</span> <span class="kn">import</span> <span class="n">VisslDatasetCatalog</span>

<span class="c1"># list all the datasets that exist in catalog</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VisslDatasetCatalog</span><span class="o">.</span><span class="n">list</span><span class="p">())</span>

<span class="c1"># get the metadata of dummy_data_folder dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VisslDatasetCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"dummy_data_folder"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:fvcore.common.file_io:** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>['dummy_data_folder']
{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Loading-Pre-trained-models-in-VISSL">Loading Pre-trained models in VISSL<a class="anchor-link" href="#Loading-Pre-trained-models-in-VISSL">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:</p>
<div class="highlight"><pre><span></span><span class="nt">WEIGHTS_INIT</span><span class="p">:</span>
  <span class="c1"># path to the .torch weights files</span>
  <span class="nt">PARAMS_FILE</span><span class="p">:</span> <span class="s">""</span>
  <span class="c1"># name of the state dict. checkpoint = {"classy_state_dict": {layername:value}}. Options:</span>
  <span class="c1">#   1. classy_state_dict - if model is trained and checkpointed with VISSL.</span>
  <span class="c1">#      checkpoint = {"classy_state_dict": {layername:value}}</span>
  <span class="c1">#   2. "" - if the model_file is not a nested dictionary for model weights i.e.</span>
  <span class="c1">#      checkpoint = {layername:value}</span>
  <span class="c1">#   3. key name that your model checkpoint uses for state_dict key name.</span>
  <span class="c1">#      checkpoint = {"your_key_name": {layername:value}}</span>
  <span class="nt">STATE_DICT_KEY_NAME</span><span class="p">:</span> <span class="s">"classy_state_dict"</span>
  <span class="c1"># specify what layer should not be loaded. Layer names with this key are not copied</span>
  <span class="c1"># By default, set to BatchNorm stats "num_batches_tracked" to be skipped.</span>
  <span class="nt">SKIP_LAYERS</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">"num_batches_tracked"</span><span class="p p-Indicator">]</span>
  <span class="c1">####### If loading a non-VISSL trained model, set the following two args carefully #########</span>
  <span class="c1"># to make the checkpoint compatible with VISSL, if you need to remove some names</span>
  <span class="c1"># from the checkpoint keys, specify the name</span>
  <span class="nt">REMOVE_PREFIX</span><span class="p">:</span> <span class="s">""</span>
  <span class="c1"># In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:</span>
  <span class="c1">#    1. If you are interested in evaluating the model features and freeze the trunk.</span>
  <span class="c1">#       Set APPEND_PREFIX="trunk.base_model." This assumes that your model is compatible</span>
  <span class="c1">#       with the VISSL trunks. The VISSL trunks start with "_feature_blocks." prefix. If</span>
  <span class="c1">#       your model doesn't have these prefix you can append them. For example:</span>
  <span class="c1">#       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk.base_model._feature_blocks."</span>
  <span class="c1">#    2. where you want to load the model simply and finetune the full model.</span>
  <span class="c1">#       Set APPEND_PREFIX="trunk."</span>
  <span class="c1">#       This assumes that your model is compatible with the VISSL trunks. The VISSL</span>
  <span class="c1">#       trunks start with "_feature_blocks." prefix. If your model doesn't have these</span>
  <span class="c1">#       prefix you can append them.</span>
  <span class="c1">#       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk._feature_blocks."</span>
  <span class="c1"># NOTE: the prefix is appended to all the layers in the model</span>
  <span class="nt">APPEND_PREFIX</span><span class="p">:</span> <span class="s">""</span>
</pre></div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extract-the-TRUNK-features">Extract the TRUNK features<a class="anchor-link" href="#Extract-the-TRUNK-features">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are ready to extract the TRUNK features now. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is <code>/path/to/my/imagenet/folder/</code>, you can add the following command line 
input to your training command:</p>
<pre><code>config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \
config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \
config.DATA.TRAIN.DATA_PATHS=["/path/to/my/imagenet/folder/train"] \
config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]</code></pre>
<p>VISSL provides a <a href="https://github.com/facebookresearch/vissl/blob/main/tools/run_distributed_engines.py">helper python tool</a> that allows to use VISSL for training purposes. This tool allows:</p>
<ul>
<li>training and feature extraction.</li>
<li>training on 1-gpu, multi-gpu, or even multi-machine using Pytorch DDP or Fairscale FSDP.</li>
</ul>
<p>VISSL provides yaml configuration files for extracting features <a href="https://github.com/facebookresearch/vissl/tree/main/configs/config/feature_extraction">here</a>.</p>
<p>For the purpose of this tutorial, we will use the config file for extracting features from several layers of the trunk of ResNet-50 supervised model on 1-gpu.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">cd</span> /content/vissl/
<span class="o">!</span>python3 tools/run_distributed_engines.py <span class="err">\</span>
    <span class="n">hydra</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="n">true</span> \
    <span class="n">config</span><span class="o">=</span><span class="n">feature_extraction</span><span class="o">/</span><span class="n">extract_resnet_in1k_8gpu</span> \
    <span class="o">+</span><span class="n">config</span><span class="o">/</span><span class="n">feature_extraction</span><span class="o">/</span><span class="n">trunk_only</span><span class="o">=</span><span class="n">rn50_layers</span><span class="o">.</span><span class="n">yaml</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_NODES</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_PROC_PER_NODE</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">CHECKPOINT</span><span class="o">.</span><span class="n">DIR</span><span class="o">=</span><span class="s2">"/content/checkpoints"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">PARAMS_FILE</span><span class="o">=</span><span class="s2">"/content/resnet50-19c8e357.pth"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">APPEND_PREFIX</span><span class="o">=</span><span class="s2">"trunk.base_model._feature_blocks."</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">STATE_DICT_KEY_NAME</span><span class="o">=</span><span class="s2">""</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">EXTRACT_FEATURES</span><span class="o">.</span><span class="n">CHUNK_THRESHOLD</span><span class="o">=-</span><span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>/content/vissl
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

####### overrides: ['hydra.verbose=true', 'config=feature_extraction/extract_resnet_in1k_8gpu', '+config/feature_extraction/trunk_only=rn50_layers.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk.base_model._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'config.EXTRACT_FEATURES.CHUNK_THRESHOLD=-1', 'hydra.verbose=true']
INFO 2021-10-14 19:02:16,814 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:51497
INFO 2021-10-14 19:02:16,814 extract_features.py:  80: Env set for rank: 0, dist_rank: 0
INFO 2021-10-14 19:02:16,815 env.py:  50: CLICOLOR:	1
INFO 2021-10-14 19:02:16,815 env.py:  50: CLOUDSDK_CONFIG:	/content/.config
INFO 2021-10-14 19:02:16,815 env.py:  50: CLOUDSDK_PYTHON:	python3
INFO 2021-10-14 19:02:16,815 env.py:  50: COLAB_GPU:	1
INFO 2021-10-14 19:02:16,815 env.py:  50: CUDA_VERSION:	11.1.1
INFO 2021-10-14 19:02:16,815 env.py:  50: CUDNN_VERSION:	8.0.5.39
INFO 2021-10-14 19:02:16,815 env.py:  50: DATALAB_SETTINGS_OVERRIDES:	{"kernelManagerProxyPort":6000,"kernelManagerProxyHost":"172.28.0.3","jupyterArgs":["--ip=\"172.28.0.2\""],"debugAdapterMultiplexerPath":"/usr/local/bin/dap_multiplexer","enableLsp":true}
INFO 2021-10-14 19:02:16,815 env.py:  50: DEBIAN_FRONTEND:	noninteractive
INFO 2021-10-14 19:02:16,815 env.py:  50: ENV:	/root/.bashrc
INFO 2021-10-14 19:02:16,816 env.py:  50: GCE_METADATA_TIMEOUT:	0
INFO 2021-10-14 19:02:16,816 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:	16
INFO 2021-10-14 19:02:16,816 env.py:  50: GIT_PAGER:	cat
INFO 2021-10-14 19:02:16,816 env.py:  50: GLIBCPP_FORCE_NEW:	1
INFO 2021-10-14 19:02:16,816 env.py:  50: GLIBCXX_FORCE_NEW:	1
INFO 2021-10-14 19:02:16,816 env.py:  50: HOME:	/root
INFO 2021-10-14 19:02:16,816 env.py:  50: HOSTNAME:	3af1980960bc
INFO 2021-10-14 19:02:16,816 env.py:  50: JPY_PARENT_PID:	65
INFO 2021-10-14 19:02:16,816 env.py:  50: LANG:	en_US.UTF-8
INFO 2021-10-14 19:02:16,817 env.py:  50: LAST_FORCED_REBUILD:	20211007
INFO 2021-10-14 19:02:16,817 env.py:  50: LD_LIBRARY_PATH:	/usr/lib64-nvidia
INFO 2021-10-14 19:02:16,817 env.py:  50: LD_PRELOAD:	/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4
INFO 2021-10-14 19:02:16,817 env.py:  50: LIBRARY_PATH:	/usr/local/cuda/lib64/stubs
INFO 2021-10-14 19:02:16,817 env.py:  50: LOCAL_RANK:	0
INFO 2021-10-14 19:02:16,817 env.py:  50: MPLBACKEND:	module://ipykernel.pylab.backend_inline
INFO 2021-10-14 19:02:16,817 env.py:  50: NCCL_VERSION:	2.7.8
INFO 2021-10-14 19:02:16,817 env.py:  50: NO_GCE_CHECK:	True
INFO 2021-10-14 19:02:16,817 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:	compute,utility
INFO 2021-10-14 19:02:16,818 env.py:  50: NVIDIA_REQUIRE_CUDA:	cuda&gt;=11.1 brand=tesla,driver&gt;=418,driver&lt;419 brand=tesla,driver&gt;=440,driver&lt;441 brand=tesla,driver&gt;=450,driver&lt;451
INFO 2021-10-14 19:02:16,818 env.py:  50: NVIDIA_VISIBLE_DEVICES:	all
INFO 2021-10-14 19:02:16,818 env.py:  50: OLDPWD:	/
INFO 2021-10-14 19:02:16,818 env.py:  50: PAGER:	cat
INFO 2021-10-14 19:02:16,818 env.py:  50: PATH:	/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin
INFO 2021-10-14 19:02:16,818 env.py:  50: PWD:	/content/vissl
INFO 2021-10-14 19:02:16,818 env.py:  50: PYDEVD_USE_FRAME_EVAL:	NO
INFO 2021-10-14 19:02:16,818 env.py:  50: PYTHONPATH:	/env/python
INFO 2021-10-14 19:02:16,818 env.py:  50: PYTHONWARNINGS:	ignore:::pip._internal.cli.base_command
INFO 2021-10-14 19:02:16,818 env.py:  50: RANK:	0
INFO 2021-10-14 19:02:16,819 env.py:  50: SHELL:	/bin/bash
INFO 2021-10-14 19:02:16,819 env.py:  50: SHLVL:	1
INFO 2021-10-14 19:02:16,819 env.py:  50: TBE_CREDS_ADDR:	172.28.0.1:8008
INFO 2021-10-14 19:02:16,819 env.py:  50: TERM:	xterm-color
INFO 2021-10-14 19:02:16,819 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:	true
INFO 2021-10-14 19:02:16,819 env.py:  50: WORLD_SIZE:	1
INFO 2021-10-14 19:02:16,819 env.py:  50: _:	/usr/bin/python3
INFO 2021-10-14 19:02:16,819 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:	/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/
INFO 2021-10-14 19:02:16,819 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:02:16,820 extract_features.py:  91: Setting seed....
INFO 2021-10-14 19:02:16,820 misc.py: 173: MACHINE SEED: 0
INFO 2021-10-14 19:02:16,822 hydra_config.py: 131: Training with config:
INFO 2021-10-14 19:02:16,831 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': '/content/checkpoints',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 5,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 2,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['dummy_data_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': False,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 2,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['dummy_data_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'sample_index',
                    'MMAP_MODE': False,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                   {'name': 'CenterCrop', 'size': 224},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': -1, 'OUTPUT_DIR': ''},
 'HOOKS': {'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': False,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 10,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'CrossEntropyLoss',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': [],
                                    'num_meters': 1,
                                    'topk_values': [1]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'name': ''},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': True,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': True,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [['conv1',
                                                                        ['AvgPool2d',
                                                                         [[10,
                                                                           10],
                                                                          10,
                                                                          4]]],
                                                                       ['res2',
                                                                        ['AvgPool2d',
                                                                         [[16,
                                                                           16],
                                                                          8,
                                                                          0]]],
                                                                       ['res3',
                                                                        ['AvgPool2d',
                                                                         [[13,
                                                                           13],
                                                                          5,
                                                                          0]]],
                                                                       ['res4',
                                                                        ['AvgPool2d',
                                                                         [[8,
                                                                           8],
                                                                          3,
                                                                          0]]],
                                                                       ['res5',
                                                                        ['AvgPool2d',
                                                                         [[6,
                                                                           6],
                                                                          1,
                                                                          0]]],
                                                                       ['res5avg',
                                                                        ['Identity',
                                                                         []]]],
                                     'SHOULD_FLATTEN_FEATS': False},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,
                              'GROUP_SIZE': -1,
                              'SYNC_BN_TYPE': 'pytorch'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk.base_model._feature_blocks.',
                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': ''},
           '_MODEL_INIT_SEED': 0},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0001},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': False,
               'non_regularized_parameters': [],
               'num_epochs': 90,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.1,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [30, 60],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.1, 0.01, 0.001]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.1,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [30, 60],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.1, 0.01, 0.001]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0001},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 0,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': False}
INFO 2021-10-14 19:02:18,067 extract_features.py: 103: System config:
-------------------  ---------------------------------------------------------------
sys.platform         linux
Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]
numpy                1.19.5
Pillow               7.1.2
vissl                0.1.6 @/content/vissl/vissl
GPU available        True
GPU 0                Tesla K80
CUDA_HOME            /usr/local/cuda
torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision
hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra
classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision
tensorboard          2.6.0
apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex
cv2                  4.1.2
PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               2
On-line CPU(s) list  0,1
Thread(s) per core   2
Core(s) per socket   1
Socket(s)            1
NUMA node(s)         1
Vendor ID            GenuineIntel
CPU family           6
Model                63
Model name           Intel(R) Xeon(R) CPU @ 2.30GHz
Stepping             0
CPU MHz              2299.998
BogoMIPS             4599.99
Hypervisor vendor    KVM
Virtualization type  full
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             46080K
NUMA node0 CPU(s)    0,1
-------------------  ------------------------------
INFO 2021-10-14 19:02:18,068 trainer_main.py: 113: Using Distributed init method: tcp://localhost:51497, world_size: 1, rank: 0
INFO 2021-10-14 19:02:18,069 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2021-10-14 19:02:18,069 trainer_main.py: 134: | initialized host 3af1980960bc as rank 0 (0)
INFO 2021-10-14 19:02:20,245 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2021-10-14 19:02:20,247 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:
['/content/dummy_data/val']
INFO 2021-10-14 19:02:20,247 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:
['/content/dummy_data/val']
INFO 2021-10-14 19:02:20,247 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val
INFO 2021-10-14 19:02:20,248 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:
['/content/dummy_data/train']
INFO 2021-10-14 19:02:20,248 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:
['/content/dummy_data/train']
INFO 2021-10-14 19:02:20,248 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train
INFO 2021-10-14 19:02:20,248 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:02:20,249 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-14 19:02:20,249 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
INFO 2021-10-14 19:02:20,250 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-14 19:02:20,250 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:02:20,250 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-14 19:02:20,250 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
INFO 2021-10-14 19:02:20,251 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-14 19:02:20,251 train_task.py: 449: Building model....
INFO 2021-10-14 19:02:20,251 feature_extractor.py:  27: Creating Feature extractor trunk...
INFO 2021-10-14 19:02:20,251 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2021-10-14 19:02:20,252 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2021-10-14 19:02:21,027 feature_extractor.py:  50: Freezing model trunk...
INFO 2021-10-14 19:02:21,028 train_task.py: 467: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_ONLY=True, will freeze trunk...
INFO 2021-10-14 19:02:21,029 base_ssl_model.py: 194: Freezing model trunk...
INFO 2021-10-14 19:02:21,029 train_task.py: 423: Initializing model from: /content/resnet50-19c8e357.pth
INFO 2021-10-14 19:02:21,030 util.py: 276: Attempting to load checkpoint from /content/resnet50-19c8e357.pth
INFO 2021-10-14 19:02:21,398 util.py: 281: Loaded checkpoint from /content/resnet50-19c8e357.pth
INFO 2021-10-14 19:02:21,399 util.py: 240: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth
INFO 2021-10-14 19:02:25,186 train_task.py: 429: Checkpoint loaded: /content/resnet50-19c8e357.pth...
INFO 2021-10-14 19:02:25,188 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,189 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,190 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,191 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,192 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,193 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,194 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,194 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,195 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,196 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,197 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,198 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,199 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,199 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,200 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,201 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,201 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,202 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,202 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,203 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,262 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,262 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,263 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,263 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,264 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,265 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,265 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,266 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,266 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,267 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,268 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,268 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,269 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,270 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,270 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,271 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,271 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,272 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:02:25,272 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,273 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,274 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,274 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,275 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,275 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,276 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,277 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,277 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,278 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,279 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,279 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,280 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:02:25,280 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,281 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,281 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,282 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,283 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,283 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,284 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,284 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,285 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,285 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,286 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,286 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,287 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,287 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,288 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,288 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,289 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,290 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,290 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,291 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,292 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,292 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,293 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,293 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,294 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,294 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,295 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,295 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,296 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:02:25,297 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,297 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,298 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:02:25,298 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,299 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,299 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,380 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,381 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,384 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,385 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,386 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,386 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,389 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,389 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,391 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,391 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,394 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,394 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,396 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,396 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,397 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,398 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,398 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,401 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:02:25,401 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,403 checkpoint.py: 886: Loaded: trunk.base_model._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:02:25,403 checkpoint.py: 851: Ignored layer:	trunk.base_model._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2021-10-14 19:02:25,403 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['trunk.base_model._feature_blocks.fc.weight', 'trunk.base_model._feature_blocks.fc.bias', 'trunk.base_model._feature_blocks.type']
INFO 2021-10-14 19:02:25,465 trainer_main.py: 352: Model is:
 Classy &lt;class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'&gt;:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): FeatureExtractorModel(
    (base_model): ResNeXt(
      (_feature_blocks): ModuleDict(
        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1_relu): ReLU(inplace=True)
        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
        (layer1): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer2): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer3): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (3): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (4): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (5): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (layer4): Sequential(
          (0): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (2): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
        )
        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
        (flatten): Flatten()
      )
    )
    (feature_pool_ops): ModuleList(
      (0): AvgPool2d(kernel_size=[10, 10], stride=10, padding=4)
      (1): AvgPool2d(kernel_size=[16, 16], stride=8, padding=0)
      (2): AvgPool2d(kernel_size=[13, 13], stride=5, padding=0)
      (3): AvgPool2d(kernel_size=[8, 8], stride=3, padding=0)
      (4): AvgPool2d(kernel_size=[6, 6], stride=1, padding=0)
      (5): Identity()
    )
  )
  (heads): ModuleList()
  (dummy_layer): Linear(in_features=4, out_features=4, bias=True)
)
INFO 2021-10-14 19:02:25,486 trainer_main.py: 362: ============== Split: TEST =======================
INFO 2021-10-14 19:02:25,486 trainer_main.py: 363: Extracting features for partition: test
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-14 19:02:31,038 trainer_main.py: 423: Model set to eval mode during feature extraction...
INFO 2021-10-14 19:02:32,473 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_features.npy
INFO 2021-10-14 19:02:32,474 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_features.npy
INFO 2021-10-14 19:02:32,475 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_targets.npy
INFO 2021-10-14 19:02:32,475 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_targets.npy
INFO 2021-10-14 19:02:32,475 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_conv1_inds.npy
INFO 2021-10-14 19:02:32,476 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_conv1_inds.npy
INFO 2021-10-14 19:02:32,476 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_features.npy
INFO 2021-10-14 19:02:32,477 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_features.npy
INFO 2021-10-14 19:02:32,477 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_targets.npy
INFO 2021-10-14 19:02:32,477 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_targets.npy
INFO 2021-10-14 19:02:32,477 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res2_inds.npy
INFO 2021-10-14 19:02:32,478 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res2_inds.npy
INFO 2021-10-14 19:02:32,478 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_features.npy
INFO 2021-10-14 19:02:32,479 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_features.npy
INFO 2021-10-14 19:02:32,479 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_targets.npy
INFO 2021-10-14 19:02:32,479 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_targets.npy
INFO 2021-10-14 19:02:32,479 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res3_inds.npy
INFO 2021-10-14 19:02:32,480 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res3_inds.npy
INFO 2021-10-14 19:02:32,480 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_features.npy
INFO 2021-10-14 19:02:32,481 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_features.npy
INFO 2021-10-14 19:02:32,481 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_targets.npy
INFO 2021-10-14 19:02:32,481 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_targets.npy
INFO 2021-10-14 19:02:32,481 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res4_inds.npy
INFO 2021-10-14 19:02:32,482 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res4_inds.npy
INFO 2021-10-14 19:02:32,482 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_features.npy
INFO 2021-10-14 19:02:32,482 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_features.npy
INFO 2021-10-14 19:02:32,483 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_targets.npy
INFO 2021-10-14 19:02:32,483 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_targets.npy
INFO 2021-10-14 19:02:32,483 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5_inds.npy
INFO 2021-10-14 19:02:32,483 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5_inds.npy
INFO 2021-10-14 19:02:32,484 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_features.npy
INFO 2021-10-14 19:02:32,484 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_features.npy
INFO 2021-10-14 19:02:32,484 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_targets.npy
INFO 2021-10-14 19:02:32,485 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_targets.npy
INFO 2021-10-14 19:02:32,485 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_res5avg_inds.npy
INFO 2021-10-14 19:02:32,485 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_res5avg_inds.npy
INFO 2021-10-14 19:02:32,486 trainer_main.py: 366: Done getting features for partition: test
INFO 2021-10-14 19:02:32,486 trainer_main.py: 362: ============== Split: TRAIN =======================
INFO 2021-10-14 19:02:32,486 trainer_main.py: 363: Extracting features for partition: train
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-14 19:02:37,747 trainer_main.py: 423: Model set to eval mode during feature extraction...
INFO 2021-10-14 19:02:37,999 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_features.npy
INFO 2021-10-14 19:02:38,001 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_features.npy
INFO 2021-10-14 19:02:38,001 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_targets.npy
INFO 2021-10-14 19:02:38,001 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_targets.npy
INFO 2021-10-14 19:02:38,001 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_conv1_inds.npy
INFO 2021-10-14 19:02:38,002 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_conv1_inds.npy
INFO 2021-10-14 19:02:38,002 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_features.npy
INFO 2021-10-14 19:02:38,003 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_features.npy
INFO 2021-10-14 19:02:38,003 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_targets.npy
INFO 2021-10-14 19:02:38,004 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_targets.npy
INFO 2021-10-14 19:02:38,004 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res2_inds.npy
INFO 2021-10-14 19:02:38,004 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res2_inds.npy
INFO 2021-10-14 19:02:38,004 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_features.npy
INFO 2021-10-14 19:02:38,005 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_features.npy
INFO 2021-10-14 19:02:38,005 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_targets.npy
INFO 2021-10-14 19:02:38,006 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_targets.npy
INFO 2021-10-14 19:02:38,006 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res3_inds.npy
INFO 2021-10-14 19:02:38,006 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res3_inds.npy
INFO 2021-10-14 19:02:38,006 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_features.npy
INFO 2021-10-14 19:02:38,007 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_features.npy
INFO 2021-10-14 19:02:38,007 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_targets.npy
INFO 2021-10-14 19:02:38,007 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_targets.npy
INFO 2021-10-14 19:02:38,008 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res4_inds.npy
INFO 2021-10-14 19:02:38,008 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res4_inds.npy
INFO 2021-10-14 19:02:38,008 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_features.npy
INFO 2021-10-14 19:02:38,009 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_features.npy
INFO 2021-10-14 19:02:38,009 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_targets.npy
INFO 2021-10-14 19:02:38,009 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_targets.npy
INFO 2021-10-14 19:02:38,009 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5_inds.npy
INFO 2021-10-14 19:02:38,010 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5_inds.npy
INFO 2021-10-14 19:02:38,010 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_features.npy
INFO 2021-10-14 19:02:38,011 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_features.npy
INFO 2021-10-14 19:02:38,011 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_targets.npy
INFO 2021-10-14 19:02:38,011 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_targets.npy
INFO 2021-10-14 19:02:38,011 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_res5avg_inds.npy
INFO 2021-10-14 19:02:38,012 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_res5avg_inds.npy
INFO 2021-10-14 19:02:38,012 trainer_main.py: 366: Done getting features for partition: train
INFO 2021-10-14 19:02:38,094 extract_features.py: 108: All Done!
INFO 2021-10-14 19:02:38,094 logger.py:  73: Shutting down loggers...
INFO 2021-10-14 19:02:38,095 distributed_launcher.py: 168: All Done!
INFO 2021-10-14 19:02:38,095 logger.py:  73: Shutting down loggers...
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we are done!! We have the features, for layers <code>conv1, res2, res3, res4, res5, res5avg</code> in <code>checkpoints/*.npy</code>. Additionally we save the data indexes and targets for each image.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls /content/checkpoints/
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>log.txt					rank0_chunk0_train_conv1_features.npy
rank0_chunk0_test_conv1_features.npy	rank0_chunk0_train_conv1_inds.npy
rank0_chunk0_test_conv1_inds.npy	rank0_chunk0_train_conv1_targets.npy
rank0_chunk0_test_conv1_targets.npy	rank0_chunk0_train_res2_features.npy
rank0_chunk0_test_res2_features.npy	rank0_chunk0_train_res2_inds.npy
rank0_chunk0_test_res2_inds.npy		rank0_chunk0_train_res2_targets.npy
rank0_chunk0_test_res2_targets.npy	rank0_chunk0_train_res3_features.npy
rank0_chunk0_test_res3_features.npy	rank0_chunk0_train_res3_inds.npy
rank0_chunk0_test_res3_inds.npy		rank0_chunk0_train_res3_targets.npy
rank0_chunk0_test_res3_targets.npy	rank0_chunk0_train_res4_features.npy
rank0_chunk0_test_res4_features.npy	rank0_chunk0_train_res4_inds.npy
rank0_chunk0_test_res4_inds.npy		rank0_chunk0_train_res4_targets.npy
rank0_chunk0_test_res4_targets.npy	rank0_chunk0_train_res5avg_features.npy
rank0_chunk0_test_res5avg_features.npy	rank0_chunk0_train_res5avg_inds.npy
rank0_chunk0_test_res5avg_inds.npy	rank0_chunk0_train_res5avg_targets.npy
rank0_chunk0_test_res5avg_targets.npy	rank0_chunk0_train_res5_features.npy
rank0_chunk0_test_res5_features.npy	rank0_chunk0_train_res5_inds.npy
rank0_chunk0_test_res5_inds.npy		rank0_chunk0_train_res5_targets.npy
rank0_chunk0_test_res5_targets.npy	train_config.yaml
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Loading-Extracted-Trunk-Features">Loading Extracted Trunk Features<a class="anchor-link" href="#Loading-Extracted-Trunk-Features">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also offer a clean and easy to use <a href="https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/utils/extract_features_utils.py">API</a> for loading and manipulating the extracted features. The features will have shape</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">vissl.utils.extract_features_utils</span> <span class="kn">import</span> <span class="n">ExtractedFeaturesLoader</span>

<span class="c1"># We will load the res5 test features</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">ExtractedFeaturesLoader</span><span class="o">.</span><span class="n">load_features</span><span class="p">(</span>
  <span class="n">input_dir</span><span class="o">=</span><span class="s2">"/content/checkpoints/"</span><span class="p">,</span>
  <span class="n">split</span><span class="o">=</span><span class="s2">"test"</span><span class="p">,</span> 
  <span class="n">layer</span><span class="o">=</span><span class="s2">"res5"</span>
<span class="p">)</span>

<span class="n">feature_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'features'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">indeces_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'inds'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">targets_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'targets'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Res5 test features have the following shape: </span><span class="si">{</span><span class="n">feature_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Res5 test indexes have the following shape: </span><span class="si">{</span><span class="n">indeces_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Res5 test targets have the following shape: </span><span class="si">{</span><span class="n">targets_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Res5 test features have the following shape: (10, 2048, 2, 2)
Res5 test indexes have the following shape: (10,)
Res5 test targets have the following shape: (10, 1)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Download-Torchvision-Model-Compatible-with-VISSL-Heads">Download Torchvision Model Compatible with VISSL Heads<a class="anchor-link" href="#Download-Torchvision-Model-Compatible-with-VISSL-Heads">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we will extract the features from the HEAD of the model. First we must download a VISSL compatible checkpoint: while we can load the torchvision TRUNK into vissl without any changes, we must slightly reformat the checkpoint to load the HEAD.</p>
<p>See <a href="https://github.com/facebookresearch/vissl/blob/main/extra_scripts/convert_vissl_to_torchvision.py">here</a> as an example for the vissl checkpoint format.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://dl.fbaipublicfiles.com/vissl/tutorials/resnet_50_torchvision_vissl_compatible.torch -P /content/
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>python3 tools/run_distributed_engines.py <span class="err">\</span>
    <span class="n">hydra</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="n">true</span> \
    <span class="n">config</span><span class="o">=</span><span class="n">feature_extraction</span><span class="o">/</span><span class="n">extract_resnet_in1k_8gpu</span> \
    <span class="o">+</span><span class="n">config</span><span class="o">/</span><span class="n">feature_extraction</span><span class="o">/</span><span class="n">with_head</span><span class="o">=</span><span class="n">rn50_supervised</span><span class="o">.</span><span class="n">yaml</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_NODES</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_PROC_PER_NODE</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">CHECKPOINT</span><span class="o">.</span><span class="n">DIR</span><span class="o">=</span><span class="s2">"/content/checkpoints"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">PARAMS_FILE</span><span class="o">=</span><span class="s2">"/content/resnet_50_torchvision_vissl_compatible.torch"</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

####### overrides: ['hydra.verbose=true', 'config=feature_extraction/extract_resnet_in1k_8gpu', '+config/feature_extraction/with_head=rn50_supervised.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet_50_torchvision_vissl_compatible.torch', 'hydra.verbose=true']
INFO 2021-10-14 19:03:35,049 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:43987
INFO 2021-10-14 19:03:35,050 extract_features.py:  80: Env set for rank: 0, dist_rank: 0
INFO 2021-10-14 19:03:35,050 env.py:  50: CLICOLOR:	1
INFO 2021-10-14 19:03:35,050 env.py:  50: CLOUDSDK_CONFIG:	/content/.config
INFO 2021-10-14 19:03:35,050 env.py:  50: CLOUDSDK_PYTHON:	python3
INFO 2021-10-14 19:03:35,050 env.py:  50: COLAB_GPU:	1
INFO 2021-10-14 19:03:35,050 env.py:  50: CUDA_VERSION:	11.1.1
INFO 2021-10-14 19:03:35,051 env.py:  50: CUDNN_VERSION:	8.0.5.39
INFO 2021-10-14 19:03:35,051 env.py:  50: DATALAB_SETTINGS_OVERRIDES:	{"kernelManagerProxyPort":6000,"kernelManagerProxyHost":"172.28.0.3","jupyterArgs":["--ip=\"172.28.0.2\""],"debugAdapterMultiplexerPath":"/usr/local/bin/dap_multiplexer","enableLsp":true}
INFO 2021-10-14 19:03:35,051 env.py:  50: DEBIAN_FRONTEND:	noninteractive
INFO 2021-10-14 19:03:35,051 env.py:  50: ENV:	/root/.bashrc
INFO 2021-10-14 19:03:35,051 env.py:  50: GCE_METADATA_TIMEOUT:	0
INFO 2021-10-14 19:03:35,051 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:	16
INFO 2021-10-14 19:03:35,051 env.py:  50: GIT_PAGER:	cat
INFO 2021-10-14 19:03:35,052 env.py:  50: GLIBCPP_FORCE_NEW:	1
INFO 2021-10-14 19:03:35,052 env.py:  50: GLIBCXX_FORCE_NEW:	1
INFO 2021-10-14 19:03:35,052 env.py:  50: HOME:	/root
INFO 2021-10-14 19:03:35,052 env.py:  50: HOSTNAME:	3af1980960bc
INFO 2021-10-14 19:03:35,052 env.py:  50: JPY_PARENT_PID:	65
INFO 2021-10-14 19:03:35,052 env.py:  50: LANG:	en_US.UTF-8
INFO 2021-10-14 19:03:35,052 env.py:  50: LAST_FORCED_REBUILD:	20211007
INFO 2021-10-14 19:03:35,052 env.py:  50: LD_LIBRARY_PATH:	/usr/lib64-nvidia
INFO 2021-10-14 19:03:35,053 env.py:  50: LD_PRELOAD:	/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4
INFO 2021-10-14 19:03:35,053 env.py:  50: LIBRARY_PATH:	/usr/local/cuda/lib64/stubs
INFO 2021-10-14 19:03:35,053 env.py:  50: LOCAL_RANK:	0
INFO 2021-10-14 19:03:35,053 env.py:  50: MPLBACKEND:	module://ipykernel.pylab.backend_inline
INFO 2021-10-14 19:03:35,053 env.py:  50: NCCL_VERSION:	2.7.8
INFO 2021-10-14 19:03:35,053 env.py:  50: NO_GCE_CHECK:	True
INFO 2021-10-14 19:03:35,053 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:	compute,utility
INFO 2021-10-14 19:03:35,054 env.py:  50: NVIDIA_REQUIRE_CUDA:	cuda&gt;=11.1 brand=tesla,driver&gt;=418,driver&lt;419 brand=tesla,driver&gt;=440,driver&lt;441 brand=tesla,driver&gt;=450,driver&lt;451
INFO 2021-10-14 19:03:35,054 env.py:  50: NVIDIA_VISIBLE_DEVICES:	all
INFO 2021-10-14 19:03:35,054 env.py:  50: OLDPWD:	/
INFO 2021-10-14 19:03:35,054 env.py:  50: PAGER:	cat
INFO 2021-10-14 19:03:35,054 env.py:  50: PATH:	/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin
INFO 2021-10-14 19:03:35,054 env.py:  50: PWD:	/content/vissl
INFO 2021-10-14 19:03:35,054 env.py:  50: PYDEVD_USE_FRAME_EVAL:	NO
INFO 2021-10-14 19:03:35,054 env.py:  50: PYTHONPATH:	/env/python
INFO 2021-10-14 19:03:35,055 env.py:  50: PYTHONWARNINGS:	ignore:::pip._internal.cli.base_command
INFO 2021-10-14 19:03:35,055 env.py:  50: RANK:	0
INFO 2021-10-14 19:03:35,055 env.py:  50: SHELL:	/bin/bash
INFO 2021-10-14 19:03:35,055 env.py:  50: SHLVL:	1
INFO 2021-10-14 19:03:35,055 env.py:  50: TBE_CREDS_ADDR:	172.28.0.1:8008
INFO 2021-10-14 19:03:35,055 env.py:  50: TERM:	xterm-color
INFO 2021-10-14 19:03:35,055 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:	true
INFO 2021-10-14 19:03:35,055 env.py:  50: WORLD_SIZE:	1
INFO 2021-10-14 19:03:35,056 env.py:  50: _:	/usr/bin/python3
INFO 2021-10-14 19:03:35,056 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:	/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/
INFO 2021-10-14 19:03:35,056 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:03:35,056 extract_features.py:  91: Setting seed....
INFO 2021-10-14 19:03:35,056 misc.py: 173: MACHINE SEED: 0
INFO 2021-10-14 19:03:35,058 hydra_config.py: 131: Training with config:
INFO 2021-10-14 19:03:35,065 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': '/content/checkpoints',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 5,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 2,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['dummy_data_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': False,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 2,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['dummy_data_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'sample_index',
                    'MMAP_MODE': False,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                   {'name': 'CenterCrop', 'size': 224},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': False,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 10,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'CrossEntropyLoss',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': [],
                                    'num_meters': 1,
                                    'topk_values': [1]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'name': ''},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': True,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': True,
                                     'FREEZE_TRUNK_ONLY': False,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],
                                     'SHOULD_FLATTEN_FEATS': True},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['mlp', {'dims': [2048, 1000]}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,
                              'GROUP_SIZE': -1,
                              'SYNC_BN_TYPE': 'pytorch'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': '',
                            'PARAMS_FILE': '/content/resnet_50_torchvision_vissl_compatible.torch',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': 'classy_state_dict'},
           '_MODEL_INIT_SEED': 0},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0001},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': False,
               'non_regularized_parameters': [],
               'num_epochs': 90,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': False,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.1,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [30, 60],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.1, 0.01, 0.001]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': False,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.1,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [30, 60],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.1, 0.01, 0.001]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0001},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 0,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': False}
INFO 2021-10-14 19:03:35,728 extract_features.py: 103: System config:
-------------------  ---------------------------------------------------------------
sys.platform         linux
Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]
numpy                1.19.5
Pillow               7.1.2
vissl                0.1.6 @/content/vissl/vissl
GPU available        True
GPU 0                Tesla K80
CUDA_HOME            /usr/local/cuda
torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision
hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra
classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision
tensorboard          2.6.0
apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex
cv2                  4.1.2
PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               2
On-line CPU(s) list  0,1
Thread(s) per core   2
Core(s) per socket   1
Socket(s)            1
NUMA node(s)         1
Vendor ID            GenuineIntel
CPU family           6
Model                63
Model name           Intel(R) Xeon(R) CPU @ 2.30GHz
Stepping             0
CPU MHz              2299.998
BogoMIPS             4599.99
Hypervisor vendor    KVM
Virtualization type  full
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             46080K
NUMA node0 CPU(s)    0,1
-------------------  ------------------------------
INFO 2021-10-14 19:03:35,728 trainer_main.py: 113: Using Distributed init method: tcp://localhost:43987, world_size: 1, rank: 0
INFO 2021-10-14 19:03:35,729 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2021-10-14 19:03:35,730 trainer_main.py: 134: | initialized host 3af1980960bc as rank 0 (0)
INFO 2021-10-14 19:03:37,831 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2021-10-14 19:03:37,832 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:
['/content/dummy_data/val']
INFO 2021-10-14 19:03:37,833 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:
['/content/dummy_data/val']
INFO 2021-10-14 19:03:37,833 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val
INFO 2021-10-14 19:03:37,833 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:
['/content/dummy_data/train']
INFO 2021-10-14 19:03:37,834 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:
['/content/dummy_data/train']
INFO 2021-10-14 19:03:37,834 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train
INFO 2021-10-14 19:03:37,834 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:03:37,834 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-14 19:03:37,834 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
INFO 2021-10-14 19:03:37,835 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-14 19:03:37,836 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-14 19:03:37,836 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-14 19:03:37,836 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
INFO 2021-10-14 19:03:37,836 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-14 19:03:37,836 train_task.py: 449: Building model....
INFO 2021-10-14 19:03:37,837 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2021-10-14 19:03:37,837 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2021-10-14 19:03:38,591 train_task.py: 473: config.MODEL.FEATURE_EVAL_SETTINGS.FREEZE_TRUNK_AND_HEAD=True, will freeze trunk and head...
INFO 2021-10-14 19:03:38,591 base_ssl_model.py: 206: Freezing model...
INFO 2021-10-14 19:03:38,592 base_ssl_model.py: 194: Freezing model trunk...
INFO 2021-10-14 19:03:38,592 base_ssl_model.py: 185: Freezing model heads...
INFO 2021-10-14 19:03:38,593 train_task.py: 423: Initializing model from: /content/resnet_50_torchvision_vissl_compatible.torch
INFO 2021-10-14 19:03:38,593 util.py: 276: Attempting to load checkpoint from /content/resnet_50_torchvision_vissl_compatible.torch
INFO 2021-10-14 19:03:38,657 util.py: 281: Loaded checkpoint from /content/resnet_50_torchvision_vissl_compatible.torch
INFO 2021-10-14 19:03:38,657 util.py: 240: Broadcasting checkpoint loaded from /content/resnet_50_torchvision_vissl_compatible.torch
INFO 2021-10-14 19:03:42,391 train_task.py: 429: Checkpoint loaded: /content/resnet_50_torchvision_vissl_compatible.torch...
INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,393 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,393 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,394 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,394 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,395 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,395 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,396 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,396 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,397 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,398 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,398 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,399 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,400 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-14 19:03:42,401 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,402 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,402 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,403 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,403 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,404 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,404 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,405 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,405 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,406 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:03:42,406 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,407 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,407 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,408 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,409 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,409 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,410 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,410 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,411 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,456 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,457 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,458 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,458 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,459 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,459 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-14 19:03:42,460 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,460 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,462 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,463 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,464 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,465 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,467 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,468 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,469 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,470 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,471 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,473 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,474 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,475 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,476 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,477 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,478 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,479 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,480 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,481 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,481 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,482 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,482 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,483 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-14 19:03:42,483 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,484 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-14 19:03:42,484 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,485 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,486 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,488 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,564 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,565 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,566 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,567 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,569 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,570 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,570 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,570 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,571 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,572 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,572 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,572 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,574 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,575 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,575 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,575 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,576 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,577 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,577 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,577 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,578 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,579 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,579 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,579 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2021-10-14 19:03:42,581 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-14 19:03:42,581 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,582 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-14 19:03:42,582 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,583 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,584 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,584 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-14 19:03:42,584 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2021-10-14 19:03:42,586 checkpoint.py: 886: Loaded: heads.0.clf.0.weight                                            of shape: torch.Size([1000, 2048]) from checkpoint
INFO 2021-10-14 19:03:42,586 checkpoint.py: 886: Loaded: heads.0.clf.0.bias                                              of shape: torch.Size([1000]) from checkpoint
INFO 2021-10-14 19:03:42,586 checkpoint.py: 901: Extra layers not loaded from checkpoint: []
INFO 2021-10-14 19:03:42,645 trainer_main.py: 352: Model is:
 Classy &lt;class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'&gt;:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): ResNeXt(
    (_feature_blocks): ModuleDict(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1_relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (flatten): Flatten()
    )
  )
  (heads): ModuleList(
    (0): MLP(
      (clf): Sequential(
        (0): Linear(in_features=2048, out_features=1000, bias=True)
      )
    )
  )
  (dummy_layer): Linear(in_features=4, out_features=4, bias=True)
)
INFO 2021-10-14 19:03:42,668 trainer_main.py: 362: ============== Split: TEST =======================
INFO 2021-10-14 19:03:42,668 trainer_main.py: 363: Extracting features for partition: test
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-14 19:03:48,176 trainer_main.py: 423: Model set to eval mode during feature extraction...
INFO 2021-10-14 19:03:49,548 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_features.npy
INFO 2021-10-14 19:03:49,549 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_features.npy
INFO 2021-10-14 19:03:49,549 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_targets.npy
INFO 2021-10-14 19:03:49,549 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_targets.npy
INFO 2021-10-14 19:03:49,550 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_test_heads_inds.npy
INFO 2021-10-14 19:03:49,550 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_test_heads_inds.npy
INFO 2021-10-14 19:03:49,573 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_features.npy
INFO 2021-10-14 19:03:49,573 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_features.npy
INFO 2021-10-14 19:03:49,573 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_targets.npy
INFO 2021-10-14 19:03:49,574 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_targets.npy
INFO 2021-10-14 19:03:49,574 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_test_heads_inds.npy
INFO 2021-10-14 19:03:49,574 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_test_heads_inds.npy
INFO 2021-10-14 19:03:49,596 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_features.npy
INFO 2021-10-14 19:03:49,597 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_features.npy
INFO 2021-10-14 19:03:49,597 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_targets.npy
INFO 2021-10-14 19:03:49,597 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_targets.npy
INFO 2021-10-14 19:03:49,597 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_test_heads_inds.npy
INFO 2021-10-14 19:03:49,598 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_test_heads_inds.npy
INFO 2021-10-14 19:03:49,620 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_features.npy
INFO 2021-10-14 19:03:49,621 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_features.npy
INFO 2021-10-14 19:03:49,621 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_targets.npy
INFO 2021-10-14 19:03:49,621 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_targets.npy
INFO 2021-10-14 19:03:49,622 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_test_heads_inds.npy
INFO 2021-10-14 19:03:49,622 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_test_heads_inds.npy
INFO 2021-10-14 19:03:49,679 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_features.npy
INFO 2021-10-14 19:03:49,680 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_features.npy
INFO 2021-10-14 19:03:49,680 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_targets.npy
INFO 2021-10-14 19:03:49,681 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_targets.npy
INFO 2021-10-14 19:03:49,681 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_test_heads_inds.npy
INFO 2021-10-14 19:03:49,681 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_test_heads_inds.npy
INFO 2021-10-14 19:03:49,681 trainer_main.py: 366: Done getting features for partition: test
INFO 2021-10-14 19:03:49,681 trainer_main.py: 362: ============== Split: TRAIN =======================
INFO 2021-10-14 19:03:49,682 trainer_main.py: 363: Extracting features for partition: train
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-14 19:03:55,125 trainer_main.py: 423: Model set to eval mode during feature extraction...
INFO 2021-10-14 19:03:55,154 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_features.npy
INFO 2021-10-14 19:03:55,154 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_features.npy
INFO 2021-10-14 19:03:55,154 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_targets.npy
INFO 2021-10-14 19:03:55,155 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_targets.npy
INFO 2021-10-14 19:03:55,155 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk0_train_heads_inds.npy
INFO 2021-10-14 19:03:55,156 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk0_train_heads_inds.npy
INFO 2021-10-14 19:03:55,178 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_features.npy
INFO 2021-10-14 19:03:55,178 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_features.npy
INFO 2021-10-14 19:03:55,178 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_targets.npy
INFO 2021-10-14 19:03:55,179 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_targets.npy
INFO 2021-10-14 19:03:55,179 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk1_train_heads_inds.npy
INFO 2021-10-14 19:03:55,179 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk1_train_heads_inds.npy
INFO 2021-10-14 19:03:55,201 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_features.npy
INFO 2021-10-14 19:03:55,202 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_features.npy
INFO 2021-10-14 19:03:55,202 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_targets.npy
INFO 2021-10-14 19:03:55,202 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_targets.npy
INFO 2021-10-14 19:03:55,203 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk2_train_heads_inds.npy
INFO 2021-10-14 19:03:55,203 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk2_train_heads_inds.npy
INFO 2021-10-14 19:03:55,225 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_features.npy
INFO 2021-10-14 19:03:55,226 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_features.npy
INFO 2021-10-14 19:03:55,226 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_targets.npy
INFO 2021-10-14 19:03:55,226 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_targets.npy
INFO 2021-10-14 19:03:55,226 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk3_train_heads_inds.npy
INFO 2021-10-14 19:03:55,227 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk3_train_heads_inds.npy
INFO 2021-10-14 19:03:55,292 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_features.npy
INFO 2021-10-14 19:03:55,293 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_features.npy
INFO 2021-10-14 19:03:55,293 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_targets.npy
INFO 2021-10-14 19:03:55,293 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_targets.npy
INFO 2021-10-14 19:03:55,293 io.py:  63: Saving data to file: /content/checkpoints/rank0_chunk4_train_heads_inds.npy
INFO 2021-10-14 19:03:55,294 io.py:  89: Saved data to file: /content/checkpoints/rank0_chunk4_train_heads_inds.npy
INFO 2021-10-14 19:03:55,294 trainer_main.py: 366: Done getting features for partition: train
INFO 2021-10-14 19:03:55,381 extract_features.py: 108: All Done!
INFO 2021-10-14 19:03:55,381 logger.py:  73: Shutting down loggers...
INFO 2021-10-14 19:03:55,382 distributed_launcher.py: 168: All Done!
INFO 2021-10-14 19:03:55,382 logger.py:  73: Shutting down loggers...
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we are done!! We have the features for the output of the HEAD. Here we have output the features, the data indexes, and the targets of each image.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>ls /content/checkpoints/ <span class="p">|</span> grep heads
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>rank0_chunk0_test_heads_features.npy
rank0_chunk0_test_heads_inds.npy
rank0_chunk0_test_heads_targets.npy
rank0_chunk0_train_heads_features.npy
rank0_chunk0_train_heads_inds.npy
rank0_chunk0_train_heads_targets.npy
rank0_chunk1_test_heads_features.npy
rank0_chunk1_test_heads_inds.npy
rank0_chunk1_test_heads_targets.npy
rank0_chunk1_train_heads_features.npy
rank0_chunk1_train_heads_inds.npy
rank0_chunk1_train_heads_targets.npy
rank0_chunk2_test_heads_features.npy
rank0_chunk2_test_heads_inds.npy
rank0_chunk2_test_heads_targets.npy
rank0_chunk2_train_heads_features.npy
rank0_chunk2_train_heads_inds.npy
rank0_chunk2_train_heads_targets.npy
rank0_chunk3_test_heads_features.npy
rank0_chunk3_test_heads_inds.npy
rank0_chunk3_test_heads_targets.npy
rank0_chunk3_train_heads_features.npy
rank0_chunk3_train_heads_inds.npy
rank0_chunk3_train_heads_targets.npy
rank0_chunk4_test_heads_features.npy
rank0_chunk4_test_heads_inds.npy
rank0_chunk4_test_heads_targets.npy
rank0_chunk4_train_heads_features.npy
rank0_chunk4_train_heads_inds.npy
rank0_chunk4_train_heads_targets.npy
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Extract-the-Output-of-the-Model-Head">Extract the Output of the Model Head<a class="anchor-link" href="#Extract-the-Output-of-the-Model-Head">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are ready to extract the HEAD now. We will reuse the same dataset and base configuration and change a few configuration options.</p>
<p>In the launch_distributed command above, we will replace</p>
<pre><code>+config/trunk_only=feature_extraction/trunk_only=rn50_layers.yaml \</code></pre>
<p>with the following:</p>
<pre><code>+config/trunk_only=feature_extraction/with_head=rn50_supervised.yaml \</code></pre>
<p>Taking a look at the differences between the two config options</p>
<div class="highlight"><pre><span></span><span class="c1"># feature_extraction/trunk_only/rn50_layers.yaml</span>
<span class="c1"># @package _global_</span>
<span class="nt">config</span><span class="p">:</span>
  <span class="nt">MODEL</span><span class="p">:</span>
    <span class="nt">FEATURE_EVAL_SETTINGS</span><span class="p">:</span>
      <span class="nt">EVAL_MODE_ON</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
      <span class="nt">FREEZE_TRUNK_ONLY</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
      <span class="nt">EXTRACT_TRUNK_FEATURES_ONLY</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
      <span class="nt">SHOULD_FLATTEN_FEATS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>
      <span class="nt">LINEAR_EVAL_FEAT_POOL_OPS_MAP</span><span class="p">:</span> <span class="p p-Indicator">[</span>
        <span class="p p-Indicator">[</span><span class="s">"conv1"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"AvgPool2d"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[[</span><span class="nv">10</span><span class="p p-Indicator">,</span> <span class="nv">10</span><span class="p p-Indicator">],</span> <span class="nv">10</span><span class="p p-Indicator">,</span> <span class="nv">4</span><span class="p p-Indicator">]]],</span>
        <span class="p p-Indicator">[</span><span class="s">"res2"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"AvgPool2d"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[[</span><span class="nv">16</span><span class="p p-Indicator">,</span> <span class="nv">16</span><span class="p p-Indicator">],</span> <span class="nv">8</span><span class="p p-Indicator">,</span> <span class="nv">0</span><span class="p p-Indicator">]]],</span>
        <span class="p p-Indicator">[</span><span class="s">"res3"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"AvgPool2d"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[[</span><span class="nv">13</span><span class="p p-Indicator">,</span> <span class="nv">13</span><span class="p p-Indicator">],</span> <span class="nv">5</span><span class="p p-Indicator">,</span> <span class="nv">0</span><span class="p p-Indicator">]]],</span>
        <span class="p p-Indicator">[</span><span class="s">"res4"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"AvgPool2d"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[[</span><span class="nv">8</span><span class="p p-Indicator">,</span> <span class="nv">8</span><span class="p p-Indicator">],</span> <span class="nv">3</span><span class="p p-Indicator">,</span> <span class="nv">0</span><span class="p p-Indicator">]]],</span>
        <span class="p p-Indicator">[</span><span class="s">"res5"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"AvgPool2d"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[[</span><span class="nv">6</span><span class="p p-Indicator">,</span> <span class="nv">6</span><span class="p p-Indicator">],</span> <span class="nv">1</span><span class="p p-Indicator">,</span> <span class="nv">0</span><span class="p p-Indicator">]]],</span>
        <span class="p p-Indicator">[</span><span class="s">"res5avg"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[</span><span class="s">"Identity"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">[]]],</span>
      <span class="p p-Indicator">]</span>
    <span class="nt">TRUNK</span><span class="p">:</span>
      <span class="nt">NAME</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">resnet</span>
      <span class="nt">RESNETS</span><span class="p">:</span>
        <span class="nt">DEPTH</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
  <span class="nt">EXTRACT_FEATURES</span><span class="p">:</span>
    <span class="nt">CHUNK_THRESHOLD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">-1</span>
</pre></div>
<div class="highlight"><pre><span></span><span class="c1"># feature_extraction/with_head/rn50_supervised.yaml</span>
<span class="c1"># @package _global_</span>
<span class="nt">config</span><span class="p">:</span>
  <span class="nt">MODEL</span><span class="p">:</span>
    <span class="nt">FEATURE_EVAL_SETTINGS</span><span class="p">:</span>
      <span class="nt">EVAL_MODE_ON</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
      <span class="nt">FREEZE_TRUNK_AND_HEAD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
      <span class="nt">EVAL_TRUNK_AND_HEAD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">True</span>
    <span class="nt">TRUNK</span><span class="p">:</span>
      <span class="nt">NAME</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">resnet</span>
      <span class="nt">RESNETS</span><span class="p">:</span>
        <span class="nt">DEPTH</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
    <span class="nt">HEAD</span><span class="p">:</span>
      <span class="nt">PARAMS</span><span class="p">:</span> <span class="p p-Indicator">[</span>
        <span class="p p-Indicator">[</span><span class="s">"mlp"</span><span class="p p-Indicator">,</span> <span class="p p-Indicator">{</span><span class="s">"dims"</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">2048</span><span class="p p-Indicator">,</span> <span class="nv">1000</span><span class="p p-Indicator">]}],</span>
      <span class="p p-Indicator">]</span>
  <span class="nt">EXTRACT_FEATURES</span><span class="p">:</span>
    <span class="nt">CHUNK_THRESHOLD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">-1</span>
</pre></div>
<ul>
<li>For both configs we set <code>EVAL_MODE_ON: True</code>.</li>
<li>Since we are not training, we want to freeze the weights. For extracting the TRUNK, we set: <code>FREEZE_TRUNK_ONLY: True</code>, whereas for extracting the HEAD, we set <code>FREEZE_TRUNK_AND_HEAD: True</code>. </li>
<li>To extract the TRUNK features, we set <code>EXTRACT_TRUNK_FEATURES_ONLY: True</code>, since we want to preserve the tensor's shape, we set <code>SHOULD_FLATTEN_FEATS: False</code>, and finally we specify the layers we want to extract in <code>LINEAR_EVAL_FEAT_POOL_OPS_MAP</code>.</li>
<li>To extract the HEAD, we set <code>EVAL_TRUNK_AND_HEAD: True</code>. We also need to specify the HEAD model, here we have a (2048,1000),fully-connected linear layer from the TRUNK to the model output. And finally, </li>
<li>Finally CHUNK_THRESHOLD controls how many features to accumulate before writing them to disk. The option of <code>-1</code> means to keep all in memory before writing to disk.</li>
</ul>
<p>As a reminder please check the <code>vissl/config/defaults.yaml</code> file for more information on all config options.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Loading-Extracted-Head-Features">Loading Extracted Head Features<a class="anchor-link" href="#Loading-Extracted-Head-Features">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using the same <a href="https://github.com/facebookresearch/vissl/blob/v0.1.6/vissl/utils/extract_features_utils.py">API</a> as above, we can load the HEAD features.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">vissl.utils.extract_features_utils</span> <span class="kn">import</span> <span class="n">ExtractedFeaturesLoader</span>

<span class="c1"># We will load the res5 test features</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">ExtractedFeaturesLoader</span><span class="o">.</span><span class="n">load_features</span><span class="p">(</span>
  <span class="n">input_dir</span><span class="o">=</span><span class="s2">"/content/checkpoints/"</span><span class="p">,</span>
  <span class="n">split</span><span class="o">=</span><span class="s2">"train"</span><span class="p">,</span> 
  <span class="n">layer</span><span class="o">=</span><span class="s2">"heads"</span>
<span class="p">)</span>

<span class="c1"># Access the shapes of each of the features.</span>
<span class="n">feature_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'features'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">indeces_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'inds'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">targets_shape</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s1">'targets'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Head train features have the following shape: </span><span class="si">{</span><span class="n">feature_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Head train indexes have the following shape: </span><span class="si">{</span><span class="n">indeces_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Head train targets have the following shape: </span><span class="si">{</span><span class="n">targets_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Head train features have the following shape: (10, 1000)
Head train indexes have the following shape: (10,)
Head train targets have the following shape: (10, 1)
</pre>
</div>
</div>
</div>
</div>
</div>
</div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><div class="social"><a class="github-button" href="https://github.com/facebookresearch/vissl" data-count-href="https://github.com/facebookresearch/vissl/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star VISSL on GitHub">vissl</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2021 Facebook Inc<br/>Legal:<a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></section></footer></div></body></html>