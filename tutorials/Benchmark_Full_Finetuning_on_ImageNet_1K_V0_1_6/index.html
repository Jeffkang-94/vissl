<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>VISSL · A library for state-of-the-art self-supervised learning from images</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="A library for state-of-the-art self-supervised learning from images"/><meta property="og:title" content="VISSL · A library for state-of-the-art self-supervised learning from images"/><meta property="og:type" content="website"/><meta property="og:url" content="https://vissl.ai/"/><meta property="og:description" content="A library for state-of-the-art self-supervised learning from images"/><meta property="og:image" content="https://vissl.ai/img/vissllogo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://vissl.ai/img/vissllogo.svg"/><link rel="shortcut icon" href="/img/visslfavicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-172675973-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/visslfavicon.png" alt="VISSL"/><h2 class="headerTitleWithLogo">VISSL</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/tutorials" target="_self">Tutorials</a></li><li class=""><a href="https://vissl.readthedocs.io/" target="_self">Docs</a></li><li class=""><a href="https://github.com/facebookresearch/vissl" target="_self">GitHub</a></li><li class=""><a target="_self"></a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Tutorials</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Getting Started</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Installation_v0_1_6">Installation</a></li><li class="navListItem"><a class="navItem" href="/tutorials/Understanding_VISSL_Training_and_YAML_Config_V0_1_6">Understanding VISSL Training and YAML Config</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Training</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Train_SimCLR_on_1_gpu_V0_1_6">Train SimCLR on 1-gpu</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Feature Extraction</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Feature_Extraction_V0_1_6">Feature Extraction</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Benchmark</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Benchmark_Linear_Image_Classification_on_ImageNet_1K_V0_1_6">Benchmark Linear Image Classification on ImageNet-1K</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6">Benchmark Full-Finetuning on ImageNet-1K</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Large Scale Training</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Large_Scale_Training_V0_1_6">Large Scale Training with VISSL (fp16, LARC, ZeRO, etc)</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Inference</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/Using_a_pretrained_model_for_inference_V0_1_6">Using a pretrained model for inference</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="tutorialButtonsWrapper"><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.ipynb" target="_blank"><img class="colabButton" align="left" src="/img/colab_icon.png"/>Run in Google Colab</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.ipynb" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Jupyter Notebook</a></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="/files/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.py" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Source Code</a></div></div><div class="tutorialBody">
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js">
</script>
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js">
</script>
<div class="notebook">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/facebookresearch/vissl/blob/v0.1.6/tutorials/Benchmark_Full_Finetuning_on_ImageNet_1K_V0_1_6.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All rights reserved.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Benchmark-Full-Finetuning-on-ImageNet-1K">Benchmark Full-Finetuning on ImageNet-1K<a class="anchor-link" href="#Benchmark-Full-Finetuning-on-ImageNet-1K">¶</a></h1><p>In this tutorial, we look at a simple example of how to use VISSL to run full finetuning benchmark for a <a href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16">ResNet-50 Torchvision pre-trained model</a>. This benchmark initializes the model trunk, attaches a linear classification head on top of the trunk features and trains the full model.</p>
<p>You can make a copy of this tutorial by <code>File -&gt; Open in playground mode</code> and make changes there. Please do <em>NOT</em> request access to this tutorial.</p>
<p><strong>NOTE:</strong> Please ensure your Collab Notebook has a GPU available. To ensure this, simply follow: <code>Edit -&gt; Notebook Settings -&gt; select GPU.</code></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install-VISSL">Install VISSL<a class="anchor-link" href="#Install-VISSL">¶</a></h2><p>Installing VISSL is pretty straightfoward. We will use pip binaries of VISSL and follow instructions from <a href="https://github.com/facebookresearch/vissl/blob/master/INSTALL.md#install-vissl-pip-package">here</a>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Install pytorch version 1.8</span>
<span class="o">!</span>pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.8.0+cu101 <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html

<span class="c1"># install Apex by checking system settings: cuda version, pytorch version, and python version</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">version_str</span><span class="o">=</span><span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
    <span class="sa">f</span><span class="s2">"py3</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">minor</span><span class="si">}</span><span class="s2">_cu"</span><span class="p">,</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"."</span><span class="p">,</span><span class="s2">""</span><span class="p">),</span>
    <span class="sa">f</span><span class="s2">"_pyt</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span>
<span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">version_str</span><span class="p">)</span>

<span class="c1"># install apex (pre-compiled with optimizer C++ extensions and CUDA kernels)</span>
<span class="o">!</span>pip install apex -f https://dl.fbaipublicfiles.com/vissl/packaging/apexwheels/<span class="o">{</span>version_str<span class="o">}</span>/download.html

<span class="c1"># # clone vissl repository and checkout latest version.</span>
<span class="o">!</span>git clone --recursive https://github.com/facebookresearch/vissl.git

<span class="o">%</span><span class="k">cd</span> vissl/

<span class="o">!</span>git checkout v0.1.6
<span class="o">!</span>git checkout -b v0.1.6

<span class="c1"># install vissl dependencies</span>
<span class="o">!</span>pip install --progress-bar off -r requirements.txt
<span class="o">!</span>pip install opencv-python

<span class="c1"># update classy vision install to commit compatible with v0.1.6</span>
<span class="o">!</span>pip uninstall -y classy_vision
<span class="o">!</span>pip install classy-vision@https://github.com/facebookresearch/ClassyVision/tarball/4785d5ee19d3bcedd5b28c1eb51ea1f59188b54d

<span class="c1"># Update fairscale to commit compatible with v0.1.6</span>
<span class="o">!</span>pip uninstall -y fairscale
<span class="o">!</span>pip install fairscale@https://github.com/facebookresearch/fairscale/tarball/df7db85cef7f9c30a5b821007754b96eb1f977b6

<span class="c1"># install vissl dev mode (e stands for editable)</span>
<span class="o">!</span>pip install -e .<span class="o">[</span>dev<span class="o">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>VISSL should be successfuly installed by now and all the dependencies should be available.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">vissl</span>
<span class="kn">import</span> <span class="nn">tensorboard</span>
<span class="kn">import</span> <span class="nn">apex</span>
<span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-the-ResNet-50-weights-from-Torchvision">Download the ResNet-50 weights from Torchvision<a class="anchor-link" href="#Download-the-ResNet-50-weights-from-Torchvision">¶</a></h2><p>We download the weights from the <a href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L16">torchvision ResNet50 model</a>:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget https://download.pytorch.org/models/resnet50-19c8e357.pth -P /content/
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-a-custom-data">Creating a custom data<a class="anchor-link" href="#Creating-a-custom-data">¶</a></h2><p>For the purpose of this tutorial, since we don't have ImageNet on the disk, we will create a dummy dataset by copying an image from COCO dataset in ImageNet dataset folder style as below:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>mkdir -p /content/dummy_data/train/class1
<span class="o">!</span>mkdir -p /content/dummy_data/train/class2
<span class="o">!</span>mkdir -p /content/dummy_data/val/class1
<span class="o">!</span>mkdir -p /content/dummy_data/val/class2

<span class="c1"># create 2 classes in train and add 5 images per class</span>
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class1/img5.jpg

<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/train/class2/img5.jpg

<span class="c1"># create 2 classes in val and add 5 images per class</span>
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class1/img5.jpg

<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img1.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img2.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img3.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img4.jpg
<span class="o">!</span>wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O /content/dummy_data/val/class2/img5.jpg
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Using-the-custom-data-in-VISSL">Using the custom data in VISSL<a class="anchor-link" href="#Using-the-custom-data-in-VISSL">¶</a></h2><p>Next step for us is to register the dummy data we created above with VISSL. Registering the dataset involves telling VISSL about the dataset name and the paths for the dataset. For this, we create a simple json file with the metadata and save it to <code>configs/config/dataset_catalog.py</code> file.</p>
<p><strong>NOTE</strong>: VISSL uses the specific <code>dataset_catalog.json</code> under the path <code>configs/config/dataset_catalog.json</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">json_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"dummy_data_folder"</span><span class="p">:</span> <span class="p">{</span>
      <span class="s2">"train"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">"/content/dummy_data/train"</span><span class="p">,</span> <span class="s2">"/content/dummy_data/train"</span>
      <span class="p">],</span>
      <span class="s2">"val"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s2">"/content/dummy_data/val"</span><span class="p">,</span> <span class="s2">"/content/dummy_data/val"</span>
      <span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># use VISSL's api to save or you can use your custom code.</span>
<span class="kn">from</span> <span class="nn">vissl.utils.io</span> <span class="kn">import</span> <span class="n">save_file</span>
<span class="n">save_file</span><span class="p">(</span><span class="n">json_data</span><span class="p">,</span> <span class="s2">"/content/vissl/configs/config/dataset_catalog.json"</span><span class="p">,</span> <span class="n">append_to_json</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we verify that the dataset is registered with VISSL. For that we query VISSL's dataset catalog as below:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">vissl.data.dataset_catalog</span> <span class="kn">import</span> <span class="n">VisslDatasetCatalog</span>

<span class="c1"># list all the datasets that exist in catalog</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VisslDatasetCatalog</span><span class="o">.</span><span class="n">list</span><span class="p">())</span>

<span class="c1"># get the metadata of dummy_data_folder dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="n">VisslDatasetCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"dummy_data_folder"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:fvcore.common.file_io:** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>['dummy_data_folder']
{'train': ['/content/dummy_data/train', '/content/dummy_data/train'], 'val': ['/content/dummy_data/val', '/content/dummy_data/val']}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Run-Full-Finetuning">Run Full-Finetuning<a class="anchor-link" href="#Run-Full-Finetuning">¶</a></h2><p>VISSL provides yaml configuration files that reproduces training of all self-supervised approaches <a href="https://github.com/facebookresearch/vissl/tree/master/configs/config/pretrain">here</a>. For the purpose of this tutorial, we will use <a href="https://github.com/facebookresearch/vissl/blob/master/configs/config/benchmark/imagenet1k_fulltune/eval_resnet_8gpu_transfer_in1k_fulltune.yaml">this config file</a> for full-finetuning a ResNet-50 supervised model on 1-gpu. Let's go ahead and download the <a href="https://github.com/facebookresearch/vissl/blob/master/configs/config/benchmark/imagenet1k_fulltune/eval_resnet_8gpu_transfer_in1k_fulltune.yaml">example config file</a>.</p>
<p>VISSL provides a <a href="https://github.com/facebookresearch/vissl/blob/main/tools/run_distributed_engines.py">helper python tool</a> that allows you to train models based on our configuration system. This tool allows:</p>
<ul>
<li>training and feature extraction.</li>
<li>training on 1-gpu, multi-gpu, or even multi-machine using Pytorch DDP or Fairscale FSDP.</li>
<li>allows training and feature extraction both using VISSL. </li>
<li>also allows training on 1-gpu or multi-gpu. </li>
<li>can be used to launch multi-machine distributed training.</li>
</ul>
<p>We are ready to run the full-finetuning. For the purpose of this tutorial, we will use synthetic dataset and train on dummy images. VISSL supports training on wide range of datasets and allows adding custom datasets. Please see VISSL documentation on how to use the datasets. To train on ImageNet instead: assuming your ImageNet dataset folder path is <code>/path/to/my/imagenet/folder/</code>, you can add the following command line 
input to your training command:</p>
<pre><code>config.DATA.TRAIN.DATASET_NAMES=[imagenet1k_folder] \
config.DATA.TRAIN.DATA_SOURCES=[disk_folder] \
config.DATA.TRAIN.DATA_PATHS=["/path/to/my/imagenet/folder/train"] \
config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]</code></pre>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The training command looks like:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>python3 tools/run_distributed_engines.py <span class="err">\</span>
    <span class="n">hydra</span><span class="o">.</span><span class="n">verbose</span><span class="o">=</span><span class="n">true</span> \
    <span class="n">config</span><span class="o">=</span><span class="n">benchmark</span><span class="o">/</span><span class="n">fulltune</span><span class="o">/</span><span class="n">imagenet1k</span><span class="o">/</span><span class="n">eval_resnet_8gpu_transfer_in1k_fulltune</span><span class="o">.</span><span class="n">yaml</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATA_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">LABEL_SOURCES</span><span class="o">=</span><span class="p">[</span><span class="n">disk_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">DATASET_NAMES</span><span class="o">=</span><span class="p">[</span><span class="n">dummy_data_folder</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">TEST</span><span class="o">.</span><span class="n">BATCHSIZE_PER_REPLICA</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">OPTIMIZER</span><span class="o">.</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">2</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">OPTIMIZER</span><span class="o">.</span><span class="n">param_schedulers</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.001</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">OPTIMIZER</span><span class="o">.</span><span class="n">param_schedulers</span><span class="o">.</span><span class="n">lr</span><span class="o">.</span><span class="n">milestones</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_NODES</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">DISTRIBUTED</span><span class="o">.</span><span class="n">NUM_PROC_PER_NODE</span><span class="o">=</span><span class="mi">1</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">CHECKPOINT</span><span class="o">.</span><span class="n">DIR</span><span class="o">=</span><span class="s2">"/content/checkpoints"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">PARAMS_FILE</span><span class="o">=</span><span class="s2">"/content/resnet50-19c8e357.pth"</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">APPEND_PREFIX</span><span class="o">=</span><span class="s2">"trunk._feature_blocks."</span> \
    <span class="n">config</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS_INIT</span><span class="o">.</span><span class="n">STATE_DICT_KEY_NAME</span><span class="o">=</span><span class="s2">""</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

####### overrides: ['hydra.verbose=true', 'config=benchmark/fulltune/imagenet1k/eval_resnet_8gpu_transfer_in1k_fulltune.yaml', 'config.DATA.TRAIN.DATA_SOURCES=[disk_folder]', 'config.DATA.TRAIN.LABEL_SOURCES=[disk_folder]', 'config.DATA.TRAIN.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TRAIN.BATCHSIZE_PER_REPLICA=2', 'config.DATA.TEST.DATA_SOURCES=[disk_folder]', 'config.DATA.TEST.LABEL_SOURCES=[disk_folder]', 'config.DATA.TEST.DATASET_NAMES=[dummy_data_folder]', 'config.DATA.TEST.BATCHSIZE_PER_REPLICA=2', 'config.OPTIMIZER.num_epochs=2', 'config.OPTIMIZER.param_schedulers.lr.values=[0.01,0.001]', 'config.OPTIMIZER.param_schedulers.lr.milestones=[1]', 'config.DISTRIBUTED.NUM_NODES=1', 'config.DISTRIBUTED.NUM_PROC_PER_NODE=1', 'config.CHECKPOINT.DIR=/content/checkpoints', 'config.MODEL.WEIGHTS_INIT.PARAMS_FILE=/content/resnet50-19c8e357.pth', 'config.MODEL.WEIGHTS_INIT.APPEND_PREFIX=trunk._feature_blocks.', 'config.MODEL.WEIGHTS_INIT.STATE_DICT_KEY_NAME=', 'hydra.verbose=true']
INFO 2021-10-18 00:57:13,053 distributed_launcher.py: 184: Spawning process for node_id: 0, local_rank: 0, dist_rank: 0, dist_run_id: localhost:57775
INFO 2021-10-18 00:57:13,053 train.py:  94: Env set for rank: 0, dist_rank: 0
INFO 2021-10-18 00:57:13,053 env.py:  50: CLICOLOR:	1
INFO 2021-10-18 00:57:13,054 env.py:  50: CLOUDSDK_CONFIG:	/content/.config
INFO 2021-10-18 00:57:13,054 env.py:  50: CLOUDSDK_PYTHON:	python3
INFO 2021-10-18 00:57:13,054 env.py:  50: COLAB_GPU:	1
INFO 2021-10-18 00:57:13,054 env.py:  50: CUDA_VERSION:	11.1.1
INFO 2021-10-18 00:57:13,054 env.py:  50: CUDNN_VERSION:	8.0.5.39
INFO 2021-10-18 00:57:13,054 env.py:  50: DATALAB_SETTINGS_OVERRIDES:	{"kernelManagerProxyPort":6000,"kernelManagerProxyHost":"172.28.0.3","jupyterArgs":["--ip=\"172.28.0.2\""],"debugAdapterMultiplexerPath":"/usr/local/bin/dap_multiplexer","enableLsp":true}
INFO 2021-10-18 00:57:13,054 env.py:  50: DEBIAN_FRONTEND:	noninteractive
INFO 2021-10-18 00:57:13,054 env.py:  50: ENV:	/root/.bashrc
INFO 2021-10-18 00:57:13,055 env.py:  50: GCE_METADATA_TIMEOUT:	0
INFO 2021-10-18 00:57:13,055 env.py:  50: GCS_READ_CACHE_BLOCK_SIZE_MB:	16
INFO 2021-10-18 00:57:13,055 env.py:  50: GIT_PAGER:	cat
INFO 2021-10-18 00:57:13,055 env.py:  50: GLIBCPP_FORCE_NEW:	1
INFO 2021-10-18 00:57:13,055 env.py:  50: GLIBCXX_FORCE_NEW:	1
INFO 2021-10-18 00:57:13,055 env.py:  50: HOME:	/root
INFO 2021-10-18 00:57:13,055 env.py:  50: HOSTNAME:	0440442413ae
INFO 2021-10-18 00:57:13,055 env.py:  50: JPY_PARENT_PID:	67
INFO 2021-10-18 00:57:13,055 env.py:  50: LANG:	en_US.UTF-8
INFO 2021-10-18 00:57:13,056 env.py:  50: LAST_FORCED_REBUILD:	20211007
INFO 2021-10-18 00:57:13,056 env.py:  50: LD_LIBRARY_PATH:	/usr/lib64-nvidia
INFO 2021-10-18 00:57:13,056 env.py:  50: LD_PRELOAD:	/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4
INFO 2021-10-18 00:57:13,056 env.py:  50: LIBRARY_PATH:	/usr/local/cuda/lib64/stubs
INFO 2021-10-18 00:57:13,056 env.py:  50: LOCAL_RANK:	0
INFO 2021-10-18 00:57:13,056 env.py:  50: MPLBACKEND:	module://ipykernel.pylab.backend_inline
INFO 2021-10-18 00:57:13,056 env.py:  50: NCCL_VERSION:	2.7.8
INFO 2021-10-18 00:57:13,056 env.py:  50: NO_GCE_CHECK:	True
INFO 2021-10-18 00:57:13,056 env.py:  50: NVIDIA_DRIVER_CAPABILITIES:	compute,utility
INFO 2021-10-18 00:57:13,057 env.py:  50: NVIDIA_REQUIRE_CUDA:	cuda&gt;=11.1 brand=tesla,driver&gt;=418,driver&lt;419 brand=tesla,driver&gt;=440,driver&lt;441 brand=tesla,driver&gt;=450,driver&lt;451
INFO 2021-10-18 00:57:13,057 env.py:  50: NVIDIA_VISIBLE_DEVICES:	all
INFO 2021-10-18 00:57:13,057 env.py:  50: OLDPWD:	/
INFO 2021-10-18 00:57:13,057 env.py:  50: PAGER:	cat
INFO 2021-10-18 00:57:13,057 env.py:  50: PATH:	/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin
INFO 2021-10-18 00:57:13,057 env.py:  50: PWD:	/content/vissl
INFO 2021-10-18 00:57:13,057 env.py:  50: PYDEVD_USE_FRAME_EVAL:	NO
INFO 2021-10-18 00:57:13,057 env.py:  50: PYTHONPATH:	/env/python
INFO 2021-10-18 00:57:13,057 env.py:  50: PYTHONWARNINGS:	ignore:::pip._internal.cli.base_command
INFO 2021-10-18 00:57:13,057 env.py:  50: RANK:	0
INFO 2021-10-18 00:57:13,058 env.py:  50: SHELL:	/bin/bash
INFO 2021-10-18 00:57:13,058 env.py:  50: SHLVL:	1
INFO 2021-10-18 00:57:13,058 env.py:  50: TBE_CREDS_ADDR:	172.28.0.1:8008
INFO 2021-10-18 00:57:13,058 env.py:  50: TERM:	xterm-color
INFO 2021-10-18 00:57:13,058 env.py:  50: TF_FORCE_GPU_ALLOW_GROWTH:	true
INFO 2021-10-18 00:57:13,058 env.py:  50: WORLD_SIZE:	1
INFO 2021-10-18 00:57:13,058 env.py:  50: _:	/usr/bin/python3
INFO 2021-10-18 00:57:13,058 env.py:  50: __EGL_VENDOR_LIBRARY_DIRS:	/usr/lib64-nvidia:/usr/share/glvnd/egl_vendor.d/
INFO 2021-10-18 00:57:13,058 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-18 00:57:13,059 train.py: 105: Setting seed....
INFO 2021-10-18 00:57:13,059 misc.py: 173: MACHINE SEED: 2
INFO 2021-10-18 00:57:13,061 hydra_config.py: 131: Training with config:
INFO 2021-10-18 00:57:13,068 hydra_config.py: 140: {'CHECKPOINT': {'APPEND_DISTR_RUN_ID': False,
                'AUTO_RESUME': True,
                'BACKEND': 'disk',
                'CHECKPOINT_FREQUENCY': 1,
                'CHECKPOINT_ITER_FREQUENCY': -1,
                'DIR': '/content/checkpoints',
                'LATEST_CHECKPOINT_RESUME_FILE_NUM': 1,
                'OVERWRITE_EXISTING': False,
                'USE_SYMLINK_CHECKPOINT_FOR_RESUME': False},
 'CLUSTERFIT': {'CLUSTER_BACKEND': 'faiss',
                'DATA_LIMIT': -1,
                'DATA_LIMIT_SAMPLING': {'SEED': 0},
                'FEATURES': {'DATASET_NAME': '',
                             'DATA_PARTITION': 'TRAIN',
                             'DIMENSIONALITY_REDUCTION': 0,
                             'EXTRACT': False,
                             'LAYER_NAME': '',
                             'PATH': '.',
                             'TEST_PARTITION': 'TEST'},
                'NUM_CLUSTERS': 16000,
                'NUM_ITER': 50,
                'OUTPUT_DIR': '.'},
 'DATA': {'DDP_BUCKET_CAP_MB': 25,
          'ENABLE_ASYNC_GPU_COPY': True,
          'NUM_DATALOADER_WORKERS': 5,
          'PIN_MEMORY': True,
          'TEST': {'BASE_DATASET': 'generic_ssl',
                   'BATCHSIZE_PER_REPLICA': 2,
                   'COLLATE_FUNCTION': 'default_collate',
                   'COLLATE_FUNCTION_PARAMS': {},
                   'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                   'COPY_TO_LOCAL_DISK': False,
                   'DATASET_NAMES': ['dummy_data_folder'],
                   'DATA_LIMIT': -1,
                   'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                           'SEED': 0,
                                           'SKIP_NUM_SAMPLES': 0},
                   'DATA_PATHS': [],
                   'DATA_SOURCES': ['disk_folder'],
                   'DEFAULT_GRAY_IMG_SIZE': 224,
                   'DROP_LAST': False,
                   'ENABLE_QUEUE_DATASET': False,
                   'INPUT_KEY_NAMES': ['data'],
                   'LABEL_PATHS': [],
                   'LABEL_SOURCES': ['disk_folder'],
                   'LABEL_TYPE': 'standard',
                   'MMAP_MODE': True,
                   'NEW_IMG_PATH_PREFIX': '',
                   'RANDOM_SYNTHETIC_IMAGES': False,
                   'REMOVE_IMG_PATH_PREFIX': '',
                   'TARGET_KEY_NAMES': ['label'],
                   'TRANSFORMS': [{'name': 'Resize', 'size': 256},
                                  {'name': 'CenterCrop', 'size': 224},
                                  {'name': 'ToTensor'},
                                  {'mean': [0.485, 0.456, 0.406],
                                   'name': 'Normalize',
                                   'std': [0.229, 0.224, 0.225]}],
                   'USE_DEBUGGING_SAMPLER': False,
                   'USE_STATEFUL_DISTRIBUTED_SAMPLER': False},
          'TRAIN': {'BASE_DATASET': 'generic_ssl',
                    'BATCHSIZE_PER_REPLICA': 2,
                    'COLLATE_FUNCTION': 'default_collate',
                    'COLLATE_FUNCTION_PARAMS': {},
                    'COPY_DESTINATION_DIR': '/tmp/imagenet1k/',
                    'COPY_TO_LOCAL_DISK': False,
                    'DATASET_NAMES': ['dummy_data_folder'],
                    'DATA_LIMIT': -1,
                    'DATA_LIMIT_SAMPLING': {'IS_BALANCED': False,
                                            'SEED': 0,
                                            'SKIP_NUM_SAMPLES': 0},
                    'DATA_PATHS': [],
                    'DATA_SOURCES': ['disk_folder'],
                    'DEFAULT_GRAY_IMG_SIZE': 224,
                    'DROP_LAST': False,
                    'ENABLE_QUEUE_DATASET': False,
                    'INPUT_KEY_NAMES': ['data'],
                    'LABEL_PATHS': [],
                    'LABEL_SOURCES': ['disk_folder'],
                    'LABEL_TYPE': 'standard',
                    'MMAP_MODE': True,
                    'NEW_IMG_PATH_PREFIX': '',
                    'RANDOM_SYNTHETIC_IMAGES': False,
                    'REMOVE_IMG_PATH_PREFIX': '',
                    'TARGET_KEY_NAMES': ['label'],
                    'TRANSFORMS': [{'name': 'RandomResizedCrop', 'size': 224},
                                   {'name': 'RandomHorizontalFlip'},
                                   {'name': 'ToTensor'},
                                   {'mean': [0.485, 0.456, 0.406],
                                    'name': 'Normalize',
                                    'std': [0.229, 0.224, 0.225]}],
                    'USE_DEBUGGING_SAMPLER': False,
                    'USE_STATEFUL_DISTRIBUTED_SAMPLER': False}},
 'DISTRIBUTED': {'BACKEND': 'nccl',
                 'BROADCAST_BUFFERS': True,
                 'INIT_METHOD': 'tcp',
                 'MANUAL_GRADIENT_REDUCTION': False,
                 'NCCL_DEBUG': False,
                 'NCCL_SOCKET_NTHREADS': '',
                 'NUM_NODES': 1,
                 'NUM_PROC_PER_NODE': 1,
                 'RUN_ID': 'auto'},
 'EXTRACT_FEATURES': {'CHUNK_THRESHOLD': 0, 'OUTPUT_DIR': ''},
 'HOOKS': {'LOG_GPU_STATS': True,
           'MEMORY_SUMMARY': {'DUMP_MEMORY_ON_EXCEPTION': False,
                              'LOG_ITERATION_NUM': 0,
                              'PRINT_MEMORY_SUMMARY': True},
           'MODEL_COMPLEXITY': {'COMPUTE_COMPLEXITY': False,
                                'INPUT_SHAPE': [3, 224, 224]},
           'PERF_STATS': {'MONITOR_PERF_STATS': True,
                          'PERF_STAT_FREQUENCY': -1,
                          'ROLLING_BTIME_FREQ': -1},
           'TENSORBOARD_SETUP': {'EXPERIMENT_LOG_DIR': 'tensorboard',
                                 'FLUSH_EVERY_N_MIN': 5,
                                 'LOG_DIR': '.',
                                 'LOG_PARAMS': True,
                                 'LOG_PARAMS_EVERY_N_ITERS': 310,
                                 'LOG_PARAMS_GRADIENTS': True,
                                 'USE_TENSORBOARD': False}},
 'IMG_RETRIEVAL': {'CROP_QUERY_ROI': False,
                   'DATASET_PATH': '',
                   'DEBUG_MODE': False,
                   'EVAL_BINARY_PATH': '',
                   'EVAL_DATASET_NAME': 'Paris',
                   'FEATS_PROCESSING_TYPE': '',
                   'GEM_POOL_POWER': 4.0,
                   'IMG_SCALINGS': [1],
                   'NORMALIZE_FEATURES': True,
                   'NUM_DATABASE_SAMPLES': -1,
                   'NUM_QUERY_SAMPLES': -1,
                   'NUM_TRAINING_SAMPLES': -1,
                   'N_PCA': 512,
                   'RESIZE_IMG': 1024,
                   'SAVE_FEATURES': False,
                   'SAVE_RETRIEVAL_RANKINGS_SCORES': True,
                   'SIMILARITY_MEASURE': 'cosine_similarity',
                   'SPATIAL_LEVELS': 3,
                   'TRAIN_DATASET_NAME': 'Oxford',
                   'TRAIN_PCA_WHITENING': True,
                   'USE_DISTRACTORS': False,
                   'WHITEN_IMG_LIST': ''},
 'LOG_FREQUENCY': 100,
 'LOSS': {'CrossEntropyLoss': {'ignore_index': -1},
          'barlow_twins_loss': {'embedding_dim': 8192,
                                'lambda_': 0.0051,
                                'scale_loss': 0.024},
          'bce_logits_multiple_output_single_target': {'normalize_output': False,
                                                       'reduction': 'none',
                                                       'world_size': 1},
          'cross_entropy_multiple_output_single_target': {'ignore_index': -1,
                                                          'normalize_output': False,
                                                          'reduction': 'mean',
                                                          'temperature': 1.0,
                                                          'weight': None},
          'deepclusterv2_loss': {'BATCHSIZE_PER_REPLICA': 256,
                                 'DROP_LAST': True,
                                 'kmeans_iters': 10,
                                 'memory_params': {'crops_for_mb': [0],
                                                   'embedding_dim': 128},
                                 'num_clusters': [3000, 3000, 3000],
                                 'num_crops': 2,
                                 'num_train_samples': -1,
                                 'temperature': 0.1},
          'dino_loss': {'crops_for_teacher': [0, 1],
                        'ema_center': 0.9,
                        'momentum': 0.996,
                        'normalize_last_layer': True,
                        'output_dim': 65536,
                        'student_temp': 0.1,
                        'teacher_temp_max': 0.07,
                        'teacher_temp_min': 0.04,
                        'teacher_temp_warmup_iters': 37500},
          'moco_loss': {'embedding_dim': 128,
                        'momentum': 0.999,
                        'queue_size': 65536,
                        'temperature': 0.2},
          'multicrop_simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                               'embedding_dim': 128,
                                                               'world_size': 64},
                                             'num_crops': 2,
                                             'temperature': 0.1},
          'name': 'cross_entropy_multiple_output_single_target',
          'nce_loss_with_memory': {'loss_type': 'nce',
                                   'loss_weights': [1.0],
                                   'memory_params': {'embedding_dim': 128,
                                                     'memory_size': -1,
                                                     'momentum': 0.5,
                                                     'norm_init': True,
                                                     'update_mem_on_forward': True},
                                   'negative_sampling_params': {'num_negatives': 16000,
                                                                'type': 'random'},
                                   'norm_constant': -1,
                                   'norm_embedding': True,
                                   'num_train_samples': -1,
                                   'temperature': 0.07,
                                   'update_mem_with_emb_index': -100},
          'simclr_info_nce_loss': {'buffer_params': {'effective_batch_size': 4096,
                                                     'embedding_dim': 128,
                                                     'world_size': 64},
                                   'temperature': 0.1},
          'swav_loss': {'crops_for_assign': [0, 1],
                        'embedding_dim': 128,
                        'epsilon': 0.05,
                        'normalize_last_layer': True,
                        'num_crops': 2,
                        'num_iters': 3,
                        'num_prototypes': [3000],
                        'output_dir': '.',
                        'queue': {'local_queue_length': 0,
                                  'queue_length': 0,
                                  'start_iter': 0},
                        'temp_hard_assignment_iters': 0,
                        'temperature': 0.1,
                        'use_double_precision': False},
          'swav_momentum_loss': {'crops_for_assign': [0, 1],
                                 'embedding_dim': 128,
                                 'epsilon': 0.05,
                                 'momentum': 0.99,
                                 'momentum_eval_mode_iter_start': 0,
                                 'normalize_last_layer': True,
                                 'num_crops': 2,
                                 'num_iters': 3,
                                 'num_prototypes': [3000],
                                 'queue': {'local_queue_length': 0,
                                           'queue_length': 0,
                                           'start_iter': 0},
                                 'temperature': 0.1,
                                 'use_double_precision': False}},
 'MACHINE': {'DEVICE': 'gpu'},
 'METERS': {'accuracy_list_meter': {'meter_names': [],
                                    'num_meters': 1,
                                    'topk_values': [1, 5]},
            'enable_training_meter': True,
            'mean_ap_list_meter': {'max_cpu_capacity': -1,
                                   'meter_names': [],
                                   'num_classes': 9605,
                                   'num_meters': 1},
            'name': 'accuracy_list_meter'},
 'MODEL': {'ACTIVATION_CHECKPOINTING': {'NUM_ACTIVATION_CHECKPOINTING_SPLITS': 2,
                                        'USE_ACTIVATION_CHECKPOINTING': False},
           'AMP_PARAMS': {'AMP_ARGS': {'opt_level': 'O1'},
                          'AMP_TYPE': 'apex',
                          'USE_AMP': False},
           'CUDA_CACHE': {'CLEAR_CUDA_CACHE': False, 'CLEAR_FREQ': 100},
           'FEATURE_EVAL_SETTINGS': {'EVAL_MODE_ON': True,
                                     'EVAL_TRUNK_AND_HEAD': False,
                                     'EXTRACT_TRUNK_FEATURES_ONLY': False,
                                     'FREEZE_TRUNK_AND_HEAD': False,
                                     'FREEZE_TRUNK_ONLY': False,
                                     'LINEAR_EVAL_FEAT_POOL_OPS_MAP': [],
                                     'SHOULD_FLATTEN_FEATS': True},
           'FSDP_CONFIG': {'AUTO_WRAP_THRESHOLD': 0,
                           'bucket_cap_mb': 0,
                           'clear_autocast_cache': True,
                           'compute_dtype': torch.float32,
                           'flatten_parameters': True,
                           'fp32_reduce_scatter': False,
                           'mixed_precision': True,
                           'verbose': True},
           'GRAD_CLIP': {'MAX_NORM': 1, 'NORM_TYPE': 2, 'USE_GRAD_CLIP': False},
           'HEAD': {'BATCHNORM_EPS': 1e-05,
                    'BATCHNORM_MOMENTUM': 0.1,
                    'PARAMS': [['mlp', {'dims': [2048, 1000]}]],
                    'PARAMS_MULTIPLIER': 1.0},
           'INPUT_TYPE': 'rgb',
           'MULTI_INPUT_HEAD_MAPPING': [],
           'NON_TRAINABLE_PARAMS': [],
           'SHARDED_DDP_SETUP': {'USE_SDP': False, 'reduce_buffer_size': -1},
           'SINGLE_PASS_EVERY_CROP': False,
           'SYNC_BN_CONFIG': {'CONVERT_BN_TO_SYNC_BN': False,
                              'GROUP_SIZE': -1,
                              'SYNC_BN_TYPE': 'pytorch'},
           'TEMP_FROZEN_PARAMS_ITER_MAP': [],
           'TRUNK': {'CONVIT': {'CLASS_TOKEN_IN_LOCAL_LAYERS': False,
                                'LOCALITY_DIM': 10,
                                'LOCALITY_STRENGTH': 1.0,
                                'N_GPSA_LAYERS': 10,
                                'USE_LOCAL_INIT': True},
                     'EFFICIENT_NETS': {},
                     'NAME': 'resnet',
                     'REGNET': {},
                     'RESNETS': {'DEPTH': 50,
                                 'GROUPNORM_GROUPS': 32,
                                 'GROUPS': 1,
                                 'LAYER4_STRIDE': 2,
                                 'NORM': 'BatchNorm',
                                 'STANDARDIZE_CONVOLUTIONS': False,
                                 'WIDTH_MULTIPLIER': 1,
                                 'WIDTH_PER_GROUP': 64,
                                 'ZERO_INIT_RESIDUAL': False},
                     'VISION_TRANSFORMERS': {'ATTENTION_DROPOUT_RATE': 0,
                                             'CLASSIFIER': 'token',
                                             'DROPOUT_RATE': 0,
                                             'DROP_PATH_RATE': 0,
                                             'HIDDEN_DIM': 768,
                                             'IMAGE_SIZE': 224,
                                             'MLP_DIM': 3072,
                                             'NUM_HEADS': 12,
                                             'NUM_LAYERS': 12,
                                             'PATCH_SIZE': 16,
                                             'QKV_BIAS': False,
                                             'QK_SCALE': False,
                                             'name': None},
                     'XCIT': {'ATTENTION_DROPOUT_RATE': 0,
                              'DROPOUT_RATE': 0,
                              'DROP_PATH_RATE': 0.05,
                              'ETA': 1,
                              'HIDDEN_DIM': 384,
                              'IMAGE_SIZE': 224,
                              'NUM_HEADS': 8,
                              'NUM_LAYERS': 12,
                              'PATCH_SIZE': 16,
                              'QKV_BIAS': True,
                              'QK_SCALE': False,
                              'TOKENS_NORM': True,
                              'name': None}},
           'WEIGHTS_INIT': {'APPEND_PREFIX': 'trunk._feature_blocks.',
                            'PARAMS_FILE': '/content/resnet50-19c8e357.pth',
                            'REMOVE_PREFIX': '',
                            'SKIP_LAYERS': ['num_batches_tracked'],
                            'STATE_DICT_KEY_NAME': ''},
           '_MODEL_INIT_SEED': 1},
 'MONITORING': {'MONITOR_ACTIVATION_STATISTICS': 0},
 'MULTI_PROCESSING_METHOD': 'forkserver',
 'NEAREST_NEIGHBOR': {'L2_NORM_FEATS': False, 'SIGMA': 0.1, 'TOPK': 200},
 'OPTIMIZER': {'betas': [0.9, 0.999],
               'construct_single_param_group_only': False,
               'head_optimizer_params': {'use_different_lr': False,
                                         'use_different_wd': False,
                                         'weight_decay': 0.0},
               'larc_config': {'clip': False,
                               'eps': 1e-08,
                               'trust_coefficient': 0.001},
               'momentum': 0.9,
               'name': 'sgd',
               'nesterov': True,
               'non_regularized_parameters': [],
               'num_epochs': 2,
               'param_schedulers': {'lr': {'auto_lr_scaling': {'auto_scale': True,
                                                               'base_lr_batch_size': 256,
                                                               'base_value': 0.1,
                                                               'scaling_type': 'linear'},
                                           'end_value': 0.0,
                                           'interval_scaling': [],
                                           'lengths': [],
                                           'milestones': [1],
                                           'name': 'multistep',
                                           'schedulers': [],
                                           'start_value': 0.1,
                                           'update_interval': 'epoch',
                                           'value': 0.1,
                                           'values': [0.00078125, 7.813e-05]},
                                    'lr_head': {'auto_lr_scaling': {'auto_scale': True,
                                                                    'base_lr_batch_size': 256,
                                                                    'base_value': 0.1,
                                                                    'scaling_type': 'linear'},
                                                'end_value': 0.0,
                                                'interval_scaling': [],
                                                'lengths': [],
                                                'milestones': [1],
                                                'name': 'multistep',
                                                'schedulers': [],
                                                'start_value': 0.1,
                                                'update_interval': 'epoch',
                                                'value': 0.1,
                                                'values': [0.00078125,
                                                           7.813e-05]}},
               'regularize_bias': True,
               'regularize_bn': False,
               'use_larc': False,
               'use_zero': False,
               'weight_decay': 0.0},
 'PROFILING': {'MEMORY_PROFILING': {'TRACK_BY_LAYER_MEMORY': False},
               'NUM_ITERATIONS': 10,
               'OUTPUT_FOLDER': '.',
               'PROFILED_RANKS': [0, 1],
               'RUNTIME_PROFILING': {'LEGACY_PROFILER': False,
                                     'PROFILE_CPU': True,
                                     'PROFILE_GPU': True,
                                     'USE_PROFILER': False},
               'START_ITERATION': 0,
               'STOP_TRAINING_AFTER_PROFILING': False,
               'WARMUP_ITERATIONS': 0},
 'REPRODUCIBILITY': {'CUDDN_DETERMINISTIC': False},
 'SEED_VALUE': 1,
 'SLURM': {'ADDITIONAL_PARAMETERS': {},
           'COMMENT': 'vissl job',
           'CONSTRAINT': '',
           'LOG_FOLDER': '.',
           'MEM_GB': 250,
           'NAME': 'vissl',
           'NUM_CPU_PER_PROC': 8,
           'PARTITION': '',
           'PORT_ID': 40050,
           'TIME_HOURS': 72,
           'TIME_MINUTES': 0,
           'USE_SLURM': False},
 'SVM': {'cls_list': [],
         'costs': {'base': -1.0,
                   'costs_list': [0.1, 0.01],
                   'power_range': [4, 20]},
         'cross_val_folds': 3,
         'dual': True,
         'force_retrain': False,
         'loss': 'squared_hinge',
         'low_shot': {'dataset_name': 'voc',
                      'k_values': [1, 2, 4, 8, 16, 32, 64, 96],
                      'sample_inds': [1, 2, 3, 4, 5]},
         'max_iter': 2000,
         'normalize': True,
         'penalty': 'l2'},
 'TEST_EVERY_NUM_EPOCH': 1,
 'TEST_MODEL': True,
 'TEST_ONLY': False,
 'TRAINER': {'TASK_NAME': 'self_supervision_task',
             'TRAIN_STEP_NAME': 'standard_train_step'},
 'VERBOSE': True}
INFO 2021-10-18 00:57:14,265 train.py: 117: System config:
-------------------  ---------------------------------------------------------------
sys.platform         linux
Python               3.7.12 (default, Sep 10 2021, 00:21:48) [GCC 7.5.0]
numpy                1.19.5
Pillow               7.1.2
vissl                0.1.6 @/content/vissl/vissl
GPU available        True
GPU 0                Tesla K80
CUDA_HOME            /usr/local/cuda
torchvision          0.9.0+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision
hydra                1.0.7 @/usr/local/lib/python3.7/dist-packages/hydra
classy_vision        0.7.0.dev @/usr/local/lib/python3.7/dist-packages/classy_vision
tensorboard          2.6.0
apex                 0.1 @/usr/local/lib/python3.7/dist-packages/apex
cv2                  4.1.2
PyTorch              1.8.0+cu101 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build  False
-------------------  ---------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

CPU info:
-------------------  ------------------------------
Architecture         x86_64
CPU op-mode(s)       32-bit, 64-bit
Byte Order           Little Endian
CPU(s)               2
On-line CPU(s) list  0,1
Thread(s) per core   2
Core(s) per socket   1
Socket(s)            1
NUMA node(s)         1
Vendor ID            GenuineIntel
CPU family           6
Model                63
Model name           Intel(R) Xeon(R) CPU @ 2.30GHz
Stepping             0
CPU MHz              2299.998
BogoMIPS             4599.99
Hypervisor vendor    KVM
Virtualization type  full
L1d cache            32K
L1i cache            32K
L2 cache             256K
L3 cache             46080K
NUMA node0 CPU(s)    0,1
-------------------  ------------------------------
INFO 2021-10-18 00:57:14,266 trainer_main.py: 113: Using Distributed init method: tcp://localhost:57775, world_size: 1, rank: 0
INFO 2021-10-18 00:57:14,267 distributed_c10d.py: 187: Added key: store_based_barrier_key:1 to store for rank: 0
INFO 2021-10-18 00:57:14,267 trainer_main.py: 134: | initialized host 0440442413ae as rank 0 (0)
INFO 2021-10-18 00:57:16,535 train_task.py: 181: Not using Automatic Mixed Precision
INFO 2021-10-18 00:57:16,536 train_task.py: 449: Building model....
INFO 2021-10-18 00:57:16,537 resnext.py:  68: ResNeXT trunk, supports activation checkpointing. Deactivated
INFO 2021-10-18 00:57:16,537 resnext.py:  88: Building model: ResNeXt50-1x64d-w1-BatchNorm2d
INFO 2021-10-18 00:57:17,301 train_task.py: 423: Initializing model from: /content/resnet50-19c8e357.pth
INFO 2021-10-18 00:57:17,301 util.py: 276: Attempting to load checkpoint from /content/resnet50-19c8e357.pth
INFO 2021-10-18 00:57:17,586 util.py: 281: Loaded checkpoint from /content/resnet50-19c8e357.pth
INFO 2021-10-18 00:57:17,586 util.py: 240: Broadcasting checkpoint loaded from /content/resnet50-19c8e357.pth
INFO 2021-10-18 00:57:21,459 train_task.py: 429: Checkpoint loaded: /content/resnet50-19c8e357.pth...
INFO 2021-10-18 00:57:21,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.conv1.weight                              of shape: torch.Size([64, 3, 7, 7]) from checkpoint
INFO 2021-10-18 00:57:21,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.weight                                of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.bias                                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,461 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_mean                          of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.bn1.running_var                           of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv1.weight                     of shape: torch.Size([64, 64, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,462 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,463 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,463 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,464 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.0.weight              of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.weight              of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.bias                of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_mean        of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.0.downsample.1.running_var         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,465 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.0.downsample.1.num_batches_tracked
INFO 2021-10-18 00:57:21,465 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,466 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,467 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.1.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.1.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv1.weight                     of shape: torch.Size([64, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,468 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn1.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,469 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv2.weight                     of shape: torch.Size([64, 64, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.weight                       of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.bias                         of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,469 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_mean                 of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn2.running_var                  of shape: torch.Size([64]) from checkpoint
INFO 2021-10-18 00:57:21,470 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.conv3.weight                     of shape: torch.Size([256, 64, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,470 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer1.2.bn3.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer1.2.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv1.weight                     of shape: torch.Size([128, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,471 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,472 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,472 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,473 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,473 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.0.weight              of shape: torch.Size([512, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.weight              of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.bias                of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_mean        of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.0.downsample.1.running_var         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,474 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.0.downsample.1.num_batches_tracked
INFO 2021-10-18 00:57:21,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,475 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,475 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,476 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,476 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.1.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,477 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.1.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,477 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,478 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,479 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,479 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,508 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,508 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,509 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,509 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,509 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.2.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,509 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.2.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,510 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv1.weight                     of shape: torch.Size([128, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,510 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,510 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,510 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,510 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn1.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,510 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,511 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv2.weight                     of shape: torch.Size([128, 128, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,511 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.weight                       of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,511 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.bias                         of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,511 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_mean                 of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,512 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn2.running_var                  of shape: torch.Size([128]) from checkpoint
INFO 2021-10-18 00:57:21,512 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,512 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.conv3.weight                     of shape: torch.Size([512, 128, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,512 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,512 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,513 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,513 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer2.3.bn3.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,513 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer2.3.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,513 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv1.weight                     of shape: torch.Size([256, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,514 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,514 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,514 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,514 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,514 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,515 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,515 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,516 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,516 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,516 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,516 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,516 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,517 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,517 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,517 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,517 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,517 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,518 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.0.weight              of shape: torch.Size([1024, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,518 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.weight              of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,518 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.bias                of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,518 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_mean        of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,519 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.0.downsample.1.running_var         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,519 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.0.downsample.1.num_batches_tracked
INFO 2021-10-18 00:57:21,519 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,519 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,519 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,519 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,520 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,520 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,521 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,521 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,521 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,521 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,521 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,521 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,522 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,522 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,522 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,522 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,522 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.1.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,522 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.1.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,523 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,523 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,523 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,523 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,523 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,523 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,524 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,524 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,524 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,524 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,525 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,525 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,525 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,525 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,525 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.2.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.2.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,526 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,527 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,527 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,527 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,528 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,528 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,528 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,528 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,528 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,528 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,529 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,529 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,529 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,529 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.3.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,529 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.3.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,530 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,530 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,530 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,530 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,530 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,530 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,531 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,531 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,531 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,531 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,532 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,532 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,532 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,532 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,532 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,532 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,533 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.4.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,533 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.4.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,533 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv1.weight                     of shape: torch.Size([256, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,533 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,533 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,533 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,534 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn1.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,534 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,534 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv2.weight                     of shape: torch.Size([256, 256, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,534 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.weight                       of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,535 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.bias                         of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,535 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_mean                 of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,535 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn2.running_var                  of shape: torch.Size([256]) from checkpoint
INFO 2021-10-18 00:57:21,535 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,535 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.conv3.weight                     of shape: torch.Size([1024, 256, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,536 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.weight                       of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,536 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.bias                         of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,536 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_mean                 of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,536 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer3.5.bn3.running_var                  of shape: torch.Size([1024]) from checkpoint
INFO 2021-10-18 00:57:21,536 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer3.5.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,537 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv1.weight                     of shape: torch.Size([512, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,537 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,537 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,537 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,538 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,538 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,540 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,541 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,541 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,541 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,541 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,541 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,617 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,617 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,618 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,618 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,618 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,618 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,620 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.0.weight              of shape: torch.Size([2048, 1024, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,620 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.weight              of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,621 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.bias                of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,621 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_mean        of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,621 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.0.downsample.1.running_var         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,621 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.0.downsample.1.num_batches_tracked
INFO 2021-10-18 00:57:21,622 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,622 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,622 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,622 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,623 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,623 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,625 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,625 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,625 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,625 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,625 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,626 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,627 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,627 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,627 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,627 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,627 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.1.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,627 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.1.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,629 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv1.weight                     of shape: torch.Size([512, 2048, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,629 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,629 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,629 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,629 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn1.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,629 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn1.num_batches_tracked
INFO 2021-10-18 00:57:21,631 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv2.weight                     of shape: torch.Size([512, 512, 3, 3]) from checkpoint
INFO 2021-10-18 00:57:21,632 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.weight                       of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,632 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.bias                         of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,632 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_mean                 of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,632 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn2.running_var                  of shape: torch.Size([512]) from checkpoint
INFO 2021-10-18 00:57:21,632 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn2.num_batches_tracked
INFO 2021-10-18 00:57:21,633 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.conv3.weight                     of shape: torch.Size([2048, 512, 1, 1]) from checkpoint
INFO 2021-10-18 00:57:21,634 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.weight                       of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,634 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.bias                         of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,634 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_mean                 of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,634 checkpoint.py: 886: Loaded: trunk._feature_blocks.layer4.2.bn3.running_var                  of shape: torch.Size([2048]) from checkpoint
INFO 2021-10-18 00:57:21,634 checkpoint.py: 851: Ignored layer:	trunk._feature_blocks.layer4.2.bn3.num_batches_tracked
INFO 2021-10-18 00:57:21,634 checkpoint.py: 894: Not found:		heads.0.clf.0.weight, not initialized
INFO 2021-10-18 00:57:21,634 checkpoint.py: 894: Not found:		heads.0.clf.0.bias, not initialized
INFO 2021-10-18 00:57:21,635 checkpoint.py: 901: Extra layers not loaded from checkpoint: ['trunk._feature_blocks.fc.weight', 'trunk._feature_blocks.fc.bias', 'trunk._feature_blocks.type']
INFO 2021-10-18 00:57:21,647 train_task.py: 651: Broadcast model BN buffers from primary on every forward pass
INFO 2021-10-18 00:57:21,648 classification_task.py: 387: Synchronized Batch Normalization is disabled
INFO 2021-10-18 00:57:21,690 optimizer_helper.py: 294: 
Trainable params: 161, 
Non-Trainable params: 0, 
Trunk Regularized Parameters: 53, 
Trunk Unregularized Parameters 106, 
Head Regularized Parameters: 2, 
Head Unregularized Parameters: 0 
Remaining Regularized Parameters: 0 
Remaining Unregularized Parameters: 0
INFO 2021-10-18 00:57:21,691 ssl_dataset.py: 157: Rank: 0 split: TEST Data files:
['/content/dummy_data/val']
INFO 2021-10-18 00:57:21,691 ssl_dataset.py: 160: Rank: 0 split: TEST Label files:
['/content/dummy_data/val']
INFO 2021-10-18 00:57:21,692 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/val
INFO 2021-10-18 00:57:21,692 ssl_dataset.py: 157: Rank: 0 split: TRAIN Data files:
['/content/dummy_data/train']
INFO 2021-10-18 00:57:21,692 ssl_dataset.py: 160: Rank: 0 split: TRAIN Label files:
['/content/dummy_data/train']
INFO 2021-10-18 00:57:21,692 disk_dataset.py:  86: Loaded 10 samples from folder /content/dummy_data/train
INFO 2021-10-18 00:57:21,693 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-18 00:57:21,693 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-18 00:57:21,693 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
INFO 2021-10-18 00:57:21,694 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-18 00:57:21,694 misc.py: 161: Set start method of multiprocessing to forkserver
INFO 2021-10-18 00:57:21,694 __init__.py: 126: Created the Distributed Sampler....
INFO 2021-10-18 00:57:21,694 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
INFO 2021-10-18 00:57:21,694 __init__.py: 215: Wrapping the dataloader to async device copies
INFO 2021-10-18 00:57:21,695 train_task.py: 384: Building loss...
INFO 2021-10-18 00:57:21,695 trainer_main.py: 268: Training 2 epochs
INFO 2021-10-18 00:57:21,695 trainer_main.py: 269: One epoch = 5 iterations.
INFO 2021-10-18 00:57:21,695 trainer_main.py: 270: Total 10 samples in one epoch
INFO 2021-10-18 00:57:21,695 trainer_main.py: 276: Total 10 iterations for training
INFO 2021-10-18 00:57:21,820 logger.py:  84: Mon Oct 18 00:57:21 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |
| N/A   75C    P0    77W / 149W |    562MiB / 11441MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

INFO 2021-10-18 00:57:21,822 trainer_main.py: 173: Model is:
 Classy &lt;class 'vissl.models.base_ssl_model.BaseSSLMultiInputOutputModel'&gt;:
BaseSSLMultiInputOutputModel(
  (_heads): ModuleDict()
  (trunk): ResNeXt(
    (_feature_blocks): ModuleDict(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv1_relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(&lt;SUPPORTED_L4_STRIDE.two: 2&gt;, &lt;SUPPORTED_L4_STRIDE.two: 2&gt;), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (flatten): Flatten()
    )
  )
  (heads): ModuleList(
    (0): MLP(
      (clf): Sequential(
        (0): Linear(in_features=2048, out_features=1000, bias=True)
      )
    )
  )
)
INFO 2021-10-18 00:57:21,822 trainer_main.py: 174: Loss is: CrossEntropyMultipleOutputSingleTargetLoss(
  (criterion): CrossEntropyMultipleOutputSingleTargetCriterion(
    (_losses): ModuleList()
  )
)
INFO 2021-10-18 00:57:21,829 trainer_main.py: 175: Starting training....
INFO 2021-10-18 00:57:21,829 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 0, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-18 00:57:27,492 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2021-10-18 00:57:27,494 log_hooks.py:  77: ========= Memory Summary at on_phase_start =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  101251 KB |  101251 KB |  101251 KB |     512 B  |
|       from large pool |   83416 KB |   83416 KB |   83416 KB |       0 B  |
|       from small pool |   17835 KB |   17835 KB |   17835 KB |     512 B  |
|---------------------------------------------------------------------------|
| Active memory         |  101251 KB |  101251 KB |  101251 KB |     512 B  |
|       from large pool |   83416 KB |   83416 KB |   83416 KB |       0 B  |
|       from small pool |   17835 KB |   17835 KB |   17835 KB |     512 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  143360 KB |  143360 KB |  143360 KB |       0 B  |
|       from large pool |  122880 KB |  122880 KB |  122880 KB |       0 B  |
|       from small pool |   20480 KB |   20480 KB |   20480 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   42109 KB |   42110 KB |  109570 KB |   67461 KB |
|       from large pool |   39464 KB |   39464 KB |   93800 KB |   54336 KB |
|       from small pool |    2645 KB |    2646 KB |   15770 KB |   13125 KB |
|---------------------------------------------------------------------------|
| Allocations           |     324    |     324    |     325    |       1    |
|       from large pool |      19    |      19    |      19    |       0    |
|       from small pool |     305    |     305    |     306    |       1    |
|---------------------------------------------------------------------------|
| Active allocs         |     324    |     324    |     325    |       1    |
|       from large pool |      19    |      19    |      19    |       0    |
|       from small pool |     305    |     305    |     306    |       1    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      16    |      16    |      16    |       0    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |      10    |      10    |      10    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |       9    |      17    |       8    |
|       from large pool |       6    |       6    |       6    |       0    |
|       from small pool |       3    |       5    |      11    |       8    |
|===========================================================================|


INFO 2021-10-18 00:57:27,494 state_update_hooks.py: 113: Starting phase 0 [train]
INFO 2021-10-18 00:57:28,905 log_hooks.py:  77: ========= Memory Summary at on_forward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  271503 KB |    2578 MB |   14863 MB |   14598 MB |
|       from large pool |  224816 KB |    2537 MB |   14812 MB |   14593 MB |
|       from small pool |   46687 KB |      45 MB |      50 MB |       4 MB |
|---------------------------------------------------------------------------|
| Active memory         |  271503 KB |    2578 MB |   14863 MB |   14598 MB |
|       from large pool |  224816 KB |    2537 MB |   14812 MB |   14593 MB |
|       from small pool |   46687 KB |      45 MB |      50 MB |       4 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    3038 MB |    4186 MB |   11632 MB |    8594 MB |
|       from large pool |    2988 MB |    4142 MB |   11580 MB |    8592 MB |
|       from small pool |      50 MB |      50 MB |      52 MB |       2 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  465776 KB |    1676 MB |    2792 MB |    2337 MB |
|       from large pool |  461264 KB |    1671 MB |    2752 MB |    2302 MB |
|       from small pool |    4512 KB |       6 MB |      40 MB |      35 MB |
|---------------------------------------------------------------------------|
| Allocations           |     540    |     540    |     657    |     117    |
|       from large pool |      69    |      70    |     105    |      36    |
|       from small pool |     471    |     471    |     552    |      81    |
|---------------------------------------------------------------------------|
| Active allocs         |     540    |     540    |     657    |     117    |
|       from large pool |      69    |      70    |     105    |      36    |
|       from small pool |     471    |     471    |     552    |      81    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      34    |      34    |      45    |      11    |
|       from large pool |       9    |      10    |      19    |      10    |
|       from small pool |      25    |      25    |      26    |       1    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      23    |      23    |     102    |      79    |
|       from large pool |       5    |       7    |      21    |      16    |
|       from small pool |      18    |      18    |      81    |      63    |
|===========================================================================|


INFO 2021-10-18 00:57:30,260 log_hooks.py:  77: ========= Memory Summary at on_backward =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  206433 KB |    2595 MB |   42189 MB |   41987 MB |
|       from large pool |  170992 KB |    2550 MB |   42077 MB |   41910 MB |
|       from small pool |   35441 KB |      47 MB |     111 MB |      77 MB |
|---------------------------------------------------------------------------|
| Active memory         |  206433 KB |    2595 MB |   42189 MB |   41987 MB |
|       from large pool |  170992 KB |    2550 MB |   42077 MB |   41910 MB |
|       from small pool |   35441 KB |      47 MB |     111 MB |      77 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  729088 KB |    4186 MB |   17722 MB |   17010 MB |
|       from large pool |  686080 KB |    4142 MB |   17658 MB |   16988 MB |
|       from small pool |   43008 KB |      52 MB |      64 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  506270 KB |    2176 MB |   11250 MB |   10756 MB |
|       from large pool |  498704 KB |    2171 MB |   11136 MB |   10649 MB |
|       from small pool |    7566 KB |       8 MB |     114 MB |     106 MB |
|---------------------------------------------------------------------------|
| Allocations           |     492    |     547    |    1074    |     582    |
|       from large pool |      38    |      83    |     257    |     219    |
|       from small pool |     454    |     478    |     817    |     363    |
|---------------------------------------------------------------------------|
| Active allocs         |     492    |     547    |    1074    |     582    |
|       from large pool |      38    |      83    |     257    |     219    |
|       from small pool |     454    |     478    |     817    |     363    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      29    |      35    |      58    |      29    |
|       from large pool |       8    |      10    |      26    |      18    |
|       from small pool |      21    |      26    |      32    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      34    |      34    |     348    |     314    |
|       from large pool |      12    |      13    |     130    |     118    |
|       from small pool |      22    |      22    |     218    |     196    |
|===========================================================================|


INFO 2021-10-18 00:57:30,272 log_hooks.py:  77: ========= Memory Summary at on_update =======
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  310013 KB |    2595 MB |   42391 MB |   42088 MB |
|       from large pool |  256976 KB |    2550 MB |   42244 MB |   41994 MB |
|       from small pool |   53037 KB |      52 MB |     146 MB |      94 MB |
|---------------------------------------------------------------------------|
| Active memory         |  310013 KB |    2595 MB |   42391 MB |   42088 MB |
|       from large pool |  256976 KB |    2550 MB |   42244 MB |   41994 MB |
|       from small pool |   53037 KB |      52 MB |     146 MB |      94 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  743424 KB |    4186 MB |   17736 MB |   17010 MB |
|       from large pool |  686080 KB |    4142 MB |   17658 MB |   16988 MB |
|       from small pool |   57344 KB |      56 MB |      78 MB |      22 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  433410 KB |    2176 MB |   11367 MB |   10944 MB |
|       from large pool |  429104 KB |    2171 MB |   11227 MB |   10808 MB |
|       from small pool |    4306 KB |       8 MB |     140 MB |     136 MB |
|---------------------------------------------------------------------------|
| Allocations           |     653    |     654    |    1396    |     743    |
|       from large pool |      56    |      83    |     293    |     237    |
|       from small pool |     597    |     598    |    1103    |     506    |
|---------------------------------------------------------------------------|
| Active allocs         |     653    |     654    |    1396    |     743    |
|       from large pool |      56    |      83    |     293    |     237    |
|       from small pool |     597    |     598    |    1103    |     506    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      36    |      36    |      65    |      29    |
|       from large pool |       8    |      10    |      26    |      18    |
|       from small pool |      28    |      28    |      39    |      11    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      15    |      35    |     386    |     371    |
|       from large pool |       7    |      13    |     136    |     129    |
|       from small pool |       8    |      24    |     250    |     242    |
|===========================================================================|


INFO 2021-10-18 00:57:30,272 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 0; lr: 0.00078; loss: 6.94697; btime(ms): 0; eta: 0:00:00; peak_mem(M): 2595;
INFO 2021-10-18 00:57:30,360 log_hooks.py: 277: Rank: 0; [ep: 0] iter: 1; lr: 0.00078; loss: 7.53335; btime(ms): 8577; eta: 0:01:17; peak_mem(M): 2595; max_iterations: 10;
INFO 2021-10-18 00:57:30,593 trainer_main.py: 214: Meters synced
INFO 2021-10-18 00:57:30,632 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 627
INFO 2021-10-18 00:57:30,633 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:   21.33 ms   14.32 ms
             forward:  281.86 ms  288.07 ms
        loss_compute:    0.78 ms    0.78 ms
     loss_all_reduce:    0.10 ms    0.12 ms
       meters_update:    0.52 ms    0.52 ms
            backward:  282.62 ms  311.82 ms
      optimizer_step:    7.85 ms   10.37 ms
    train_step_total:  619.58 ms  627.53 ms
INFO 2021-10-18 00:57:30,633 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 20.0}, 'top_5': {0: 40.0}}
INFO 2021-10-18 00:57:30,633 io.py:  63: Saving data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:30,634 io.py:  89: Saved data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:30,634 log_hooks.py: 426: [phase: 0] Saving checkpoint to /content/checkpoints
INFO 2021-10-18 00:57:31,134 checkpoint.py: 131: Saved checkpoint: /content/checkpoints/model_phase0.torch
INFO 2021-10-18 00:57:31,135 checkpoint.py: 140: Creating symlink...
INFO 2021-10-18 00:57:31,136 checkpoint.py: 144: Created symlink: /content/checkpoints/checkpoint.torch
INFO 2021-10-18 00:57:31,136 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 1, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-18 00:57:36,682 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2021-10-18 00:57:36,682 state_update_hooks.py: 113: Starting phase 1 [test]
INFO 2021-10-18 00:57:36,884 trainer_main.py: 214: Meters synced
INFO 2021-10-18 00:57:36,885 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 40
INFO 2021-10-18 00:57:36,885 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}
INFO 2021-10-18 00:57:36,885 io.py:  63: Saving data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:36,886 io.py:  89: Saved data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:36,886 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 2, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-18 00:57:42,361 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2021-10-18 00:57:42,362 state_update_hooks.py: 113: Starting phase 2 [train]
INFO 2021-10-18 00:57:42,509 log_hooks.py: 277: Rank: 0; [ep: 1] iter: 5; lr: 8e-05; loss: 4.80023; btime(ms): 1518; eta: 0:00:07; peak_mem(M): 2595;
INFO 2021-10-18 00:57:42,862 trainer_main.py: 214: Meters synced
INFO 2021-10-18 00:57:42,905 log_hooks.py: 568: Average train batch time (ms) for 5 batches: 108
INFO 2021-10-18 00:57:42,905 log_hooks.py: 577: Train step time breakdown (rank 0):
               Timer     Host    CudaEvent
         read_sample:   11.00 ms    3.88 ms
             forward:   27.48 ms   34.67 ms
        loss_compute:    0.65 ms    0.64 ms
     loss_all_reduce:    0.10 ms    0.10 ms
       meters_update:    0.46 ms    0.47 ms
            backward:   15.65 ms   57.23 ms
      optimizer_step:    8.85 ms   10.63 ms
    train_step_total:   99.71 ms  108.45 ms
INFO 2021-10-18 00:57:42,905 log_hooks.py: 498: Rank: 0, name: train_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}
INFO 2021-10-18 00:57:42,906 io.py:  63: Saving data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:42,906 io.py:  89: Saved data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:42,906 log_hooks.py: 426: [phase: 1] Saving checkpoint to /content/checkpoints
INFO 2021-10-18 00:57:43,403 checkpoint.py: 131: Saved checkpoint: /content/checkpoints/model_final_checkpoint_phase1.torch
INFO 2021-10-18 00:57:43,404 checkpoint.py: 140: Creating symlink...
INFO 2021-10-18 00:57:43,404 checkpoint.py: 144: Created symlink: /content/checkpoints/checkpoint.torch
INFO 2021-10-18 00:57:43,405 __init__.py: 101: Distributed Sampler config:
{'num_replicas': 1, 'rank': 0, 'epoch': 3, 'num_samples': 10, 'total_size': 10, 'shuffle': True, 'seed': 0}
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

INFO 2021-10-18 00:57:48,868 trainer_main.py: 333: Phase advanced. Rank: 0
INFO 2021-10-18 00:57:48,869 state_update_hooks.py: 113: Starting phase 3 [test]
INFO 2021-10-18 00:57:49,126 trainer_main.py: 214: Meters synced
INFO 2021-10-18 00:57:49,126 log_hooks.py: 568: Average test batch time (ms) for 5 batches: 51
INFO 2021-10-18 00:57:49,127 log_hooks.py: 498: Rank: 0, name: test_accuracy_list_meter, value: {'top_1': {0: 50.0}, 'top_5': {0: 100.0}}
INFO 2021-10-18 00:57:49,127 io.py:  63: Saving data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:49,127 io.py:  89: Saved data to file: /content/checkpoints/metrics.json
INFO 2021-10-18 00:57:49,227 train.py: 131: All Done!
INFO 2021-10-18 00:57:49,228 logger.py:  73: Shutting down loggers...
INFO 2021-10-18 00:57:49,228 distributed_launcher.py: 168: All Done!
INFO 2021-10-18 00:57:49,229 logger.py:  73: Shutting down loggers...
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we are done!! We have the full-finetuned model and the <code>metrics.json</code> containing <code>top-1</code> and <code>top-5</code> accuracy on validation set is available in <code>checkpoints/metrics.json</code>.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">ls</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">checkpoints</span><span class="o">/</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-cyan-intense-fg ansi-bold">checkpoint.torch</span>@  model_final_checkpoint_phase1.torch  train_config.yaml
log.txt            model_phase0.torch
metrics.json       stdout.json
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">cat</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">checkpoints</span><span class="o">/</span><span class="n">metrics</span><span class="o">.</span><span class="n">json</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>{"iteration": 5, "phase_idx": 0, "train_accuracy_list_meter": {"top_1": {"0": 20.0}, "top_5": {"0": 40.0}}, "train_phase_idx": 0}
{"iteration": 5, "phase_idx": 1, "test_accuracy_list_meter": {"top_1": {"0": 50.0}, "top_5": {"0": 100.0}}, "train_phase_idx": 0}
{"iteration": 10, "phase_idx": 2, "train_accuracy_list_meter": {"top_1": {"0": 50.0}, "top_5": {"0": 100.0}}, "train_phase_idx": 1}
{"iteration": 10, "phase_idx": 3, "test_accuracy_list_meter": {"top_1": {"0": 50.0}, "top_5": {"0": 100.0}}, "train_phase_idx": 1}
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Loading-Pre-trained-models-in-VISSL">Loading Pre-trained models in VISSL<a class="anchor-link" href="#Loading-Pre-trained-models-in-VISSL">¶</a></h1><p>VISSL supports Torchvision models out of the box. Generally, for loading any non-VISSL model, one needs to correctly set the following configuration options:</p>
<div class="highlight"><pre><span></span><span class="nt">WEIGHTS_INIT</span><span class="p">:</span>
  <span class="c1"># path to the .torch weights files</span>
  <span class="nt">PARAMS_FILE</span><span class="p">:</span> <span class="s">""</span>
  <span class="c1"># name of the state dict. checkpoint = {"classy_state_dict": {layername:value}}. Options:</span>
  <span class="c1">#   1. classy_state_dict - if model is trained and checkpointed with VISSL.</span>
  <span class="c1">#      checkpoint = {"classy_state_dict": {layername:value}}</span>
  <span class="c1">#   2. "" - if the model_file is not a nested dictionary for model weights i.e.</span>
  <span class="c1">#      checkpoint = {layername:value}</span>
  <span class="c1">#   3. key name that your model checkpoint uses for state_dict key name.</span>
  <span class="c1">#      checkpoint = {"your_key_name": {layername:value}}</span>
  <span class="nt">STATE_DICT_KEY_NAME</span><span class="p">:</span> <span class="s">"classy_state_dict"</span>
  <span class="c1"># specify what layer should not be loaded. Layer names with this key are not copied</span>
  <span class="c1"># By default, set to BatchNorm stats "num_batches_tracked" to be skipped.</span>
  <span class="nt">SKIP_LAYERS</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">"num_batches_tracked"</span><span class="p p-Indicator">]</span>
  <span class="c1">####### If loading a non-VISSL trained model, set the following two args carefully #########</span>
  <span class="c1"># to make the checkpoint compatible with VISSL, if you need to remove some names</span>
  <span class="c1"># from the checkpoint keys, specify the name</span>
  <span class="nt">REMOVE_PREFIX</span><span class="p">:</span> <span class="s">""</span>
  <span class="c1"># In order to load the model (if not trained with VISSL) with VISSL, there are 2 scenarios:</span>
  <span class="c1">#    1. If you are interested in evaluating the model features and freeze the trunk.</span>
  <span class="c1">#       Set APPEND_PREFIX="trunk.base_model." This assumes that your model is compatible</span>
  <span class="c1">#       with the VISSL trunks. The VISSL trunks start with "_feature_blocks." prefix. If</span>
  <span class="c1">#       your model doesn't have these prefix you can append them. For example:</span>
  <span class="c1">#       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk.base_model._feature_blocks."</span>
  <span class="c1">#    2. where you want to load the model simply and finetune the full model.</span>
  <span class="c1">#       Set APPEND_PREFIX="trunk."</span>
  <span class="c1">#       This assumes that your model is compatible with the VISSL trunks. The VISSL</span>
  <span class="c1">#       trunks start with "_feature_blocks." prefix. If your model doesn't have these</span>
  <span class="c1">#       prefix you can append them.</span>
  <span class="c1">#       For TorchVision ResNet trunk, set APPEND_PREFIX="trunk._feature_blocks."</span>
  <span class="c1"># NOTE: the prefix is appended to all the layers in the model</span>
  <span class="nt">APPEND_PREFIX</span><span class="p">:</span> <span class="s">"trunk._feature_blocks."</span>
</pre></div>
<p><strong>NOTE:</strong> The above configuration will only load the TRUNK of a torchvision model. If you wish to load the HEAD and TRUNK of a torchvision model, you will have to convert the torchvision model to a VISSL supported checkpoint.</p>
</div>
</div>
</div>
</div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div class="footerSection"><div class="social"><a class="github-button" href="https://github.com/facebookresearch/vissl" data-count-href="https://github.com/facebookresearch/vissl/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star VISSL on GitHub">vissl</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2021 Facebook Inc<br/>Legal:<a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></section></footer></div></body></html>